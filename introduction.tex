\chapter{Introduction}
\label{sec:intro}
\begin{summary}
  In this work I discuss a modification of a fluorescence microscope    \cma{my device}
  that minimizes the toxic effects of the excitation light.

  In the following introductory chapter I describe what phototoxicity   \cma{phototoxicity}
  is and how it comes about. Then I give an example of how it
  influences biological observations in a developing \celegans\ 
  embryo and describe how this particular biological system can be
  used to evaluate and compare the phototoxicity of different microscopes.

  Later in this chapter I give an overview of image formation   \cma{cameras}
  in the wide-field microscope and I describe its principle limitations
  regarding resolution and depth discrimination. Furthermore I
  discuss the two most important current image detector technologies
  --- electron multiplying charge-coupled devices (EMCCD) and
  scientifc complementary metal–oxide–semiconductor (sCMOS).
\end{summary}
Regardless of whether it is the picture of earth captured by an
orbiting satellite, the x-ray motion picture of a running dog or the
time-lapse recording of a blooming flower. Images capture our
imagination and they are a good starting point to develop new models
and theories.

This is particularly true for microscopy.  Only after people became
aware of microorganisms by direct observation, medieval quack could
finally be overcome and modern medicine based on the scientific
method flourished instead.

Even today --- with electron microscopes, magnetic resonance
tomography and sequencing machines --- optical microscopy still is an
indispensable tool for research of living organisms.

Fluorescence microscopy is of particular importance: It enables the     \cma{labelling, switching}
scientist to selectively label a particular type of molecule in living cells
and observe how they perform their biological function.

Besides localizing molecules it is possible to measure physical
quantities inside of the sample. There are, for example, fluorescent
labels that report membrane potentials or viscosity inside of cells.

Finally, it is even possible to exert a controlling function with the
excitation light: There are compounds that locally release chemicals
when illuminated and there are  genetically encoded ion channels that can be
switched by light \citep{Boyden2005}.

However, the excitation light introduces unnatural and potentially
deleterious energy into the specimen. If the exogenous light harms the
observed organism in any way, this effect is called phototoxicity.

% dennoch: from photophysical prospective of single- and multi-photon
% microcopy, probably the most disheartening reality is the occurrence
% of photobleaching and photodamage
% \citep{diaspro2009nanoscopy}

There are a number of techniques that can reduce phototoxicity: Two
photon excitation, controlled light exposure, selective plane
illumination, highly inclined and laminated optical sheet, and oblique
plane microscopy. I introduce them in
chapter \ref{sec:illum-patterns}. These techniques have different
pros and cons and not all are equally suited for a specific problem,
e.g.\ selective plane illumination is very effective, but it needs two
perpendicular lenses and can not be used for multiwell plates or to
observe the liver of a living, adult mouse.

In this work I present an approach that makes use of modern display
and camera technology. We only modify the microscope's illumination
path, the space around objective lens and specimen remains as
accessible as in any conventional wide-field microscope.



\section{Phototoxicity in life sciences and the model organism
  \celegans}
\label{sec:intro-phototoxicity}
The partner in our project who is responsible for decisions related to
life sciences and biology is Institut Pasteur (Paris, FR). They work
on infectious diseases. 

In order to motivate the importance of phototoxicity, I would like to
portray an elegant drug screening experiment which I have seen on one
of my visits in Paris: An automatic microscope continuously images a
cell culture in multiwell plates. These cells carry a pathogen. The
pathogen, the nuclei of the cultured cells and the membranes of the
cells are each stained with a different fluorophore. The cells in each
well of the plates are exposed to a different chemical.

A chemical is considered a hit and will be investigated during further
trials, when the time lapse images show that the culture cells stay
healthy and the number of pathogens decrease. As neither people nor
animals come to harm, this screening experiment is an impeccable
method to systematically understand and hopefully heal certain
diseases. However, this experiment doesn't work very well, if the
excitation light --- and not the drug --- kills the pathogens. The
effect of phototoxicity should therefore be minimized.


Now one would hardly develop a microscope and directly test it with
dangerous pathogens. As part of our collaboration, the Institut
Pasteur therefore developed a safe biological test system that is
relatively easy to maintain \citep{Stiernagle2006} and allows to test
the phototoxicity of various microscopes \citep{Tinevez2012}.




The basis of the system is the embryo of the organism \celegans. These
are small invertebrates. The adult form is approximately \unit[1]{mm}
long.  Their anatomy and development are comparatively simple and have
been well characterized \citep{Sulston1977,Durbin1987}.

\jpginput{12cm}{celegans-devel}{Phototoxic effects while imaging the
  embryonal development of three \celegans\ embryos (strain
  AZ212, histone-2B tagged with eGFP) with different excitation
  intensities. The embryo with lowest excitation dosage (left)
  develops fastest. The embryo with the highest dosage (right) ceases
  development and nearly all fluorophores are bleached after the
  experiment. Images by J.-Y. Tinevez (Institut Pasteur, Paris, FR).}
  

We use embryos of a genetically modified strain\footnote{Our strain
  has WormBase ID AZ212 \citep{Praitis2001}.} that expresses eGFP
tagged histones (enhanced green fluorescent protein, excitation
maximum \unit[488]{nm}, emission maximum \unit[509]{nm}). Histones are
incorporated into the chromatin during cell divisions, i.e.\ the
nuclei of our worms fluoresce green.  The mother worm passes a
sufficient amount of these proteins into the cytoplasm of the
embryo. In the beginning of its development the embryo entirely relies
on this reserve of histones. Only in a much later stage --- certainly
not during the first few hours, that we observe --- it will form its
own histones.

\figref{fig:celegans-devel} compares time-lapse experiments on three \cma{embryo example} 
different \celegans\ embryos with varying
excitation intensities.

The lineage tree of two developing \celegans\ embryos is the \cma{reproducible development}
same.  With all other factors being equal, particularly if the
temperature is constant at $\unit[21\pm
1]{\degreeCelsius}$, two different embryos will develop at the
same speed from egg to fertile adult in three and a half days.


At the beginning of the experiment, embryos are removed from their
mothers at an identical stage, before any cellular divisions have
occured. Then a $z-$stack of the egg with 41 slices and one micron
$z-$sampling is obtained every two minutes.

The columns in \figref{fig:celegans-devel} depict three different embryos
whose development was imaged according to this protocol for two hours
and 38 minutes with different excitation powers.

The figure displays the maximum intensity projections of the
$z-$stacks.  In order to make the cell nuclei visible in all images, I
normalized the data to the same range. As can be guessed from the
photon shot noise, the upper left image contains the least number of
fluorescence photons, and the upper right the most.

An analysis of the time-lapse data show that one hour into the
experiment the embryo with the highest excitation dose (right) has
stopped developing and its fluorophores are strongly bleached.  Some
cells even turned apoptotic and went into programmed cell death.

After two hours and 38 minutes the experiment was stopped and the
embryo which was exposed to the lowest dose (left) has developed the
largest number of cells. The middle embryo ceased developing while the
right embryo died even earlier and nearly all its fluorophores are
bleached at the end of the experiment.

In \figref{fig:worm-integration-time} I reproduce quantitative data
from \cite{Tinevez2012}. Each data point in this graph corresponds to
a two hour time-lapse imaging experiment of a \celegans\ embryo in a
wide-field microscope. From a very low excitation up to a certain
threshold dose the development isn't affected by the light and
approximately 50 cells develop during the two hours.

For a dose above the threshold the development is slowed due to
phototoxicity and the number of cells at the end of the experiment
decreases.

\gnuplotinput{worm-integration-time}{Longer exposure times are less
  phototoxic. Each data point corresponds to one embryo that developed
  under a particular excitation dose for two hours. The solid lines
  are sigmoidal fits to the data. Also indicated are the two
  phototoxicity thresholds given by the inflection point of the
  sigmoid and their $95\%$ confidence intervals. This data was
  provided by J.-Y. Tinevez (Institut Pasteur, Paris, FR) and is also
  published in \cite{Tinevez2012}.}  

The orange data points in the diagram correspond to a per slice
integration time $\tau$ of \unit[100]{ms} and for the green data
the integration time is five times higher.

\nomenclature{$\Omega$}{Excitation dose in $\joule/(\centi\meter^2\textrm{stack})$} 
\nomenclature{$\Phi_e$}{Radiant flux of excitation light in watts} 
The dose $\Omega$ on the $x-$axis is calculated as
\begin{align}
\Omega = \frac{\Phi_e n \tau}{A},
\end{align}
with integration time $\tau$, area $A$ of the illuminated field, the
number of slices $n=41$ and radiant flux $\Phi_e$ of the excitation
light, as measured in the pupil.

Naively one would assume that it shouldn't make any difference if the
excitation light dose is administered with \unit[100]{ms} or
\unit[500]{ms} exposures but these data show that a longer exposure
time and low intensity are less phototoxic.

These results agree with an earlier study in tobacco plants
\citep{Dixit2003}. They investigate cell death a few days after
illumination and find that there is a threshold dose below which no
phototoxicity can be detected, and that this threshold decreases with
light intensity. Dixit and Cyr show that the damage is caused by
reactive oxygen species and they explain the shift of the
phototoxicity threshold by the limited capacity of the cells'
scavenging system for those radicals. They also predict the existence
of redox-sensitive checkpoints in the mitotic division cycle.

%\citep{Sancar2004}

In summary this section describes how to measure phototoxicity with
biological specimen.  The next section gives an overview of the
underlying photophysics and the rest of this work describes our
attempt to build a microscope with reduced phototoxic footprint.



\section{Photophysical principles of phototoxicity}
\begin{summary}
  Here I give a short overview of fluorescence of molecules in order
  to introduce the terms photobleaching and phototoxicity.
\end{summary}
A fluorophore is a molecule that can absorb and subsequently emit
light. During the absorption of a photon the molecular orbital
transitions from the electronic ground state $S_0$ to an excited state
$S_1$. The lifetime of the excited state $S_1$ is in the order of a
few nanoseconds.
\begin{figure}[!hbt]
  \centering
  \svginput{.8}{flu-level}
  \caption{The Jablonski energy level diagram of an illustrative
    fluorescent molecule. The boxes depict orbitals, up and down
    arrows symbolize the spin of the outer electrons. Fat horizontal
    lines represent electronic states. Thinner lines indicate
    vibro-rotational states. Various processes are shown with their
    typical time scales. VR = vibro-rotational relaxation, ISC =
    intersystem crossing, IC = internal conversion \cite[inspired
    from][]{Haken2006}.}
  \label{fig:flu-level}
\end{figure}
A Jablonski diagram, as depicted in \figref{fig:flu-level}, summarizes
information \cma{energy levels} about the energy levels of a molecule
and possible transition processes.

%  If the photon has an even higher
% energy, the electron will go into the second excited singlet state
% $S_2$.

The majority of known stable and bright fluorophores absorb and emit
in the wavelength range between \unit[300]{nm} and \unit[700]{nm}.
Photons at the high energy end of this range can excite molecules into
higher energy levels $S_n, (n>1)$ than the first excited state; these
states are unstable and hardly return to the ground state $S_0$. On
the other side of the spectrum: a molecule that absorbs in the
near-infrared ($\unit[>700]{nm}$) has a low-lying excited singlet
state $S_1$ and therefore potentially increased reactivity and a high
probability for a non-radiative transfer back into the ground state
$S_0$ \citep{Sauer2011}.


The term \emph{Stokes' shift} describes the frequency shift between
the absorbed and emitted photon; the energy difference is lost as heat
to the fluorophore molecule and surrounding solvent.  For the
practical implementation of fluorescence microscopes this is
significant, as it enables to separate excitation and emission light
with a dichroic beam splitter.

A fluorescence photon is emitted into a random direction. We use this
in the next section to describe image formation in the fluorescence
microscope.


The triplet states $T_n$ play an important role in photobleaching.
Pure electronic absorption of one photon has no effect on the spin of
an electron and therefore the transition from singlet states $S_n$
into the triplet state $T_n$ shouldn't occur. However, interaction
with the nuclei can mediate this spin transition. Therefore, in
fluorophores this transition has a small probability, resulting in
long lifetimes of the triplet state $T_1$.

\cite{Deschenes2002} show that excitation of higher triplet states
$T_n$ is the predominant reactive process for photobleaching in
vacuum. In particular they measured that one rhodamine~6G molecule
\emph{in vacuum} can emit more than \num{1e9} photons before it
bleaches, if the excitation intensity is low enough
$(\sim\unit[1]{\si{\watt/\cm^2}})$ to prevent decay over triplet
states.

In normal atmosphere the prolonged lifetime of the triplet state $T_1$
makes it highly likely for the fluorophore to react with molecular
oxygen $\O_2$. Oxygen is abundant and has a triplet ground state
${}^3\Sigma$ with two unpaired electrons of parallel spin in its
$\pi^*-$orbitals (see \figref{fig:oxygen}).

  \citep{Bernas2004}

\begin{figure}[!hbt]
  \centering
  \svginput{1}{oxygen}
  \caption{{\bf left:} Schematic that depicts how the orbitals of the
    oxygen molecule are formed from the atomic orbitals. {\bf right:}
    Molecular oxygen has the lowest energy in its triplet state
    ${}^3\Sigma$ where the spins of the two outer $\pi^*-$electrons
    are parallel. Inspired from \citet{Linde2011a}.}
  \label{fig:oxygen}
\end{figure}

If a ground-state oxygen molecule comes into physical contact with a
$T_1$ fluorophore, the energy of the latter can be transferred by an
electron exchange energy transfer mechanism in which the orbitals
directly interact with each other \citetext{\citealp[p.~438]{Haken2006} and
  \citealp{Linde2011a}}.

During this reaction, which is also known as triplet--triplet
annihilation, two forms of singlet oxygen form in competition: The
lower energy state ${}^1\Delta$ and the short-lived, higher energy
state ${}^1\Sigma$ that immediately ($T_{1/2}\sim\unit[10^{-9}]{s}$)
sends out a \unit[1268]{nm} photon and decays into ${}^1\Delta$.

The resulting singlet oxygen ${}^1\Delta$ is very reactive. In a
typical specimen it diffuses only a few tens of nanometres until it
reacts with another molecule.

(FIXME 2000 greenbaum measures oxygen production, bernas 2004 anoxia gfp)

Nowadays many methods are known to reduce photobleaching: Substitute
oxygen with noble gases or remove it enzymatically
\citep[p.~89]{Sauer2011}, depopulate the triplet state by adding
reducing as well as oxidizing agents to the solvent
\citep{Vogelsang2008} or couple a triplet quencher directly to the
fluorophore \citep[p.~19]{Sauer2011}. For fixed samples it helps to
change the solvent or polymer.
 
In living specimen these techniques may reduce photobleaching, but
they can also have a detrimental effect on the biological system
itself. Removing oxygen will quite certainly have a negative
effect. In order to reduce phototoxicity it makes sense to think about
the light management in the microscope.


\section{Conventional microscopes}
\begin{summary}
  Most of the fluorescence microscopes that are in common use today do
  not excite fluorophores of the specimen in an optimal way. In
  this section I outline how these microscopes work and explain how
  out-of-focus blur severely limits the performance of the wide-field
  microscope.
\end{summary}


A microscope, is a device that collects light coming from one plane  \cma{lateral image}
and forms a magnified image on a
camera. \figref{fig:widefield-microscope}~b) shows a schematic
representation of the detection path of a wide-field microscope.

The main components are an objective lens with focal length $f$ and a \cma{telecentric arrangement}
tube lens TL1 with focal length $f_\textrm{TL}>f$. Sample, lenses and
camera are arranged in double-telecentric configuration, i.e.\ the
sample is located in the front focal plane of the objective, the tube
lens is at distance $f_\textrm{TL}$ behind the pupil and the camera is
in the focal plane behind the tube lens.


\nomenclature{$\beta$}{Transversal magnification of an objective
  $\beta=f_\mathrm{TL}/f$, for Zeiss lenses the magnification $\beta$
  is written on the objective and the focal length of the tube lens is
  defined as $f_\textrm{TL}=\unit[164.5]{mm}$}


Light from the sample is collimated by the objective lens and
\cma{lateral magnification} re-imaged by the tube lens. The lateral
magnification $\beta$ is given by the ratio of the focal lengths of
the two lenses:
\begin{align}
  \beta=\frac{\overline{O'P'}}{\overline{OP}}=\frac{f_\mathrm{TL}}{f}.
\end{align}
Note that in \figref{fig:widefield-microscope}~b) I represent the
\cma{necessary corrections} objective lens as a single element.  This
is a simplification.

In the paraxial limit ray-tracing calculations for a thick lens or
even several consecutive lens elements can be simplified by bending
the ray only at one place --- at the principal plane.

\nomenclature{marginal ray}{Axial ray through the periphery of the
  entrance aperture}

\nomenclature{chief ray}{Ray from the periphery of the field through
  the center of the entrance aperture}

\nomenclature{entrance aperture}{Projection of the limiting aperture
  of the optical system into object space}


Microscope objectives must collect light from a large aperture in
order to produce a high resolution image. This is a fact I will
support shortly using the wave-optical model. Unfortunately the large
ray angles in the objective prevent its simplified description using
principal planes, but an analysis using the eikonal theory shows that
an optical system that fulfills the Abbe Sine condition allows perfect
imaging even for widespread ray bundles.
\begin{align}
  \beta = \frac{n \sin\alpha}{n' \sin\alpha'} \qquad \textrm{(Abbe Sine condition)}
\end{align}
This condition ensures that the focal length, a quantity which is
usually defined only for paraxial rays, is equal for all angles.  This
in turn means that such a lens carries out a Fourier transform from
the front to the back focal plane with linear scaling. Note that a
lens with a non-linear distortion in the back focal plane will fail to
produce an image that is similar to the object.

It turns out that ray bending in a high-aperture lens system that
fulfills the Abbe Sine condition can be simplified to a one bend at a
single surface, quite similar to the utilization of principal planes
in paraxial optics. For a high-aperture system this surface is no
longer a plane.  Instead it is a sphere with radius $n f$ and called
\emph{aplanatic sphere}. I depict this surface as two circle segments
with bold red strokes on the lenses in
\figref{fig:widefield-microscope}~b).

In addition to the Abbe Sine condition microscope lenses are also
corrected for spherical aberration and linear coma \citep{Gross2005}.
Then the coma rays are symmetric around the chief ray, the wavefront
and point spread function are approximately invariant for small field
sizes (in first order).  This ensures that the imaging conditions are
invariant for small regions of the field plane and allows to express
image formation with linear systems theory.

\subsection{Wave-optical theory for image formation}
In the following I want to describe how the image on the camera       \cma{wave optics}
forms. For this we have to use wave theory because close to the image
rays intersect, invalidating ray-optical predictions. As both
theories are very much related, we can give a useful interpretation of
the aplanatic surface for wave optics.

The underlying Maxwell equations and the wave equation are linear and   \cma{plane waves}
we can represent propagating solutions (evanescent solutions are
neglected) of the wave equation as a superposition of the elementary
solution --- the monochromatic, plane waves described by wave vector
$\k$:
\begin{align}
  u(\r,t)=u\,\exp(i(\k\r-\omega t)),\quad \r=(r_x,r_y,r_z),\
  \k=(k_x,k_y,k_z),\ |\k|=2\pi n/\lambda_0,
\end{align}
The accurate treatment of high-aperture optics would in fact require a
vectorial calculation of the image for a fluorophore with a particular
dipole orientation.  Subsequently these images should be averaged to
account for random fluorophore orientations, but as I don't need
quantitative expressions I limit myself to the simpler scalar problem
which provides a qualitatively similar result.

% \begin{figure}[!hbt]
%   \centering
%   \svginput{1}{sine-condition}
%   \caption{dasfklj}
%   \label{fig:sine-condition}
% \end{figure}



\begin{figure}[!hbt]
  \centering
  \svginput{1}{widefield-microscope}
  \caption{{\bf a)} Transmitted segment of the three-dimensional
    frequency spectrum is highlighted in red on the Ewald sphere. {\bf
      b)} Schematic of the detection path of a modern microscope. The
    sample is in the front focal plane of the objective. The detection
    tube lens TL1 forms a magnified image on the camera. The aplanatic
    spheres for objective and tube lens are indicated in
    \textcolor{red}{red}. {\bf c)} Parallel laser epifluorescence
    excitation. The excitation tube lens TL2 focuses a laser into the
    pupil of the objective. The beam is reflected by a dichroic beam
    splitter (BS) towards the objective. An extended area in the
    specimen is illuminated. Fluorescence light returns through the
    objective, is transmitted through BS and forms an image on the
    camera. }
  \label{fig:widefield-microscope}
\end{figure}

\nomenclature{$u(\r)$}{Scalar field as a function of spatial
  coordinates} 

\nomenclature{$\widetilde u(\vnu)$}{Fourier transform
  of scalar field as a function of spatial frequencies}

\nomenclature{$\r=(r_x,r_y,r_z)^T$}{Three-dimensional spatial
  coordinate} 

\nomenclature{$\r_t=(r_x,r_y)^T$}{Transversal two-dimensional spatial
  coordinate}

\nomenclature{$\vnu=(\nu_x,\nu_y,\nu_z)^T$}{Three-dimensional spatial
  frequency}

\nomenclature{$\vnu_t=(\nu_x,\nu_y)^T$}{Transversal two-dimensional
  spatial frequency}

Assuming excited fluorophores in the sample give rise to a                 \cma{Ewald sphere}
monochromatic electromagnetic field --- again, I simplify the problem
by omitting the complication that fluorophores emit photons in a
wavelength range --- then using the spatial frequency vector
$\vnu=\k/(2\pi)$ we can expand the three-dimensional, stationary field
amplitude distribution $u(\r)$ into its spatial frequency spectrum
$\widetilde u(\vnu)$:
\begin{align}
  u(\r)=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}
  \widetilde u(\vnu) \exp(2\pi i \r\vnu)\ \textrm{d}^3 \vnu
\end{align}
Since we have assumed a monochromatic field and the length $|\vnu|$ of
the spatial frequency vector is the inverse of the wavelength, the
support of this spectrum $u(\vnu)$ is limited to the surface of a
sphere of radius $n/\lambda_0$:
\begin{align}
  \supp \widetilde u(\vnu) &= \{\vnu \in \mathbb{R}^3: |\vnu|=n/\lambda_0\}.
\end{align}
This sphere is the transfer function of free space, and is also called
Ewald sphere.  \nomenclature{Ewald sphere}{Transfer function of free
  space} Scaling the Ewald sphere with $f\lambda_0$ gives the
aplanatic surface of the lens. 

According to \cite{McCutchen1964} the transfer function $\widetilde
h(\vnu)$ of the lens is defined by complex values on the Ewald sphere. 
aperture:
\begin{align}
  \widetilde h(\vnu)&=P(\vnu_t) \exp\left(\frac{2\pi i}{\lambda} 
    W(\vnu_t)\right)
  \delta\left(|\vnu|-\frac{n}{\lambda_0}\right),
\end{align}
with the Dirac delta function $\delta$, transversal spatial frequency
vector $\vnu_t=(\nu_x,\nu_y)^T$, and the real valued pupil function
$P(\vnu_t)$ and wavefront error $W(\vnu_t)$. McCutchen calls
$\widetilde h(\vnu)$ the generalized aperture.

For this discussion I set $W(\vnu_t)=1$, i.e.\ there are no wavefront
aberration and the lens is diffraction limited. Furthermore I use a
uniform cylinder as pupil function $P(\vnu_t)$, in order to limit the
size of the calotte or cap of the Ewald sphere that is defined by the
acceptance angle $\alpha$ of the objective\footnote{Note that this
  expression is only valid for $\alpha\in[0,\pi/2]$. An expression for
  $\widetilde h(\vnu)$ encompassing the full range $[0,\pi]$ for
  $\alpha$ must contain two functions of each $P$ and $W$, in
  dependence on whether the spatial frequency vector $\vnu$ is
  directed in or against the direction of the optical axis. This is
  necessary to express the transfer function of a 4Pi microscope.}:

% \begin{align}
%   \widetilde h(\vnu) =
%   \begin{cases}
%     P_-(\vnu_t) \exp\left(\frac{2\pi i}{\lambda} 
%     W_-(\vnu_t)\right)
%   \delta\left(|\vnu|-\frac{n}{\lambda_0}\right) & \nu_z<0
%  \\
% P_+(\vnu_t) \exp\left(\frac{2\pi i}{\lambda} 
%     W_+(\vnu_t)\right)
%   \delta\left(|\vnu|-\frac{n}{\lambda_0}\right) & \nu_z\ge 0
%   \end{cases}
% \end{align}

\begin{align}
  P(\vnu_t) &=
  H\left(|\vnu_t|-\frac{n\sin(\alpha)}{\lambda_0}\right), \quad \textrm{with}\ 
  H(x)=
  \begin{cases} 
    1 & x\ge 0 \\
    0 & x<0 
  \end{cases}
\end{align}
where $H(x)$ is the step function. In general $P(\vnu_t)$ can assume
values between 0 and 1 in order to account for apodization due to
Fresnel reflection or natural vignetting. I ignore these effects here.

Multiplication of the angular frequency spectrum $\widetilde u(\vnu)$
with the generalized aperture $\widetilde h(\vnu)$ gives the angular
frequency spectrum of the amplitude in the image:
\begin{align}
  \widetilde u'(\vnu) = \widetilde u(\vnu)\cdot \widetilde h(\vnu).
\end{align}
According to the convolution theorem this multiplication of the
spectra corresponds to a convolution of the field distribution $u(\r)$
and an amplitude point spread function $h(\r)=\mathcal{F}(\widetilde
h(\vnu))$ that describes the imaging of the objective lens:
\begin{align}
  u'(\r) = u(\r) \otimes h(\r) =
  \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}
  u(\r')\ h(\r-\r')\ \textrm{d}^3\r'.
\end{align}


with the
three-dimensional frequency spectrum  of the
sample as shown in \figref{fig:widefield-microscope}~a).




transversal spatial frequencies $\vnu_t=(\nu_x,\nu_y)$

Die Pupille begrenzt die durchgelassenen Strahlbuendel und wirkt damit
als low-pass filter auf das Ortsfrequenzspektrum. Falls das System
Aberrationen aufweist, koennte man diese hier mit der Wellenfront
$W(\vnu_t)$ einfuegn. Durch multiplikation mit der Funktion $\widetilde h$ 

diffraction limited W=1




Faltungstheorem
\begin{align}
  \mathcal{F}[\widetilde h(\vnu_t)\widetilde u(\vnu_t)]
\end{align}


angularly band-limited


\begin{align}
  A &= \frac{f}{d} = \frac{1}{2\tan\alpha}\\
  h_r(\vnu_t,\nu_z)&=\frac{1}{2\pi\nu_t A}\sqrt{1-\left(\frac{2A\nu_z}{\nu_t}\right)^2}
\end{align}

The Ewald sphere allows an intuitive calculation of the transfer
function of a microscope. The low-pass 

The pupil works as a filte




no absorption or diffraction in sample
random fluorophores
recording successive slices, telecentricity, real microscope 
main results: image formation linear in intensity, three dimensionally shift-invariant

missing cone \cite{Streibl1984}


- note that $\nu_z$ can be expressed in terms of the other components,
  replacing in the exponential inside the integral acoordingly gives
  with $= U(\nu_x,\nu_y,\nu_z)/cos(\alpha)$

$$ u(x,y,z)=\int\int U_\textrm{2D}(\nu_x,\nu_y)|_{z=0}  exp(2\pi i (x \nu_x+y\nu_y+z\sqrt{(n/\lambda)^2-\nu_x^2-\nu_y^2})) d \nu_x d \nu_y$$

- the aperture angle $\alpha$ defines the maximum transversal freq of
   the spectrum of a 3d scalar point response function

- the 3d freq spectrum is given by a segment of the ewald sphere
  (which mccutchen calls generalized aperture)

- based on this, one can estimate the transversal distribution of the
  psf I(r,z=0) and the axial psf I(r=0,z)

- first order born approximation:

    - light is deflected only by a single interaction 

    - diffraction is linear in frequency space: diffracted spectrum $U_s$ is
      given by the convolution of the incident spectrum $U_i$ with object
      spectrum f

$$U_s(\nu_x,\nu_y,\nu_z) \sim f(\nu_x,\nu_y,\nu_z) \otimes U_i(\nu_x,\nu_y,\nu_z)$$

    - if $U_i$ is a planar wave, then the scattered wave is just the
      object spectrum shifted by the frequency of the incoming wave

    -single moment transfer: only those frequencies $\vec\gamma$ are
     transferred forr which the laue equation is satisfied

$$\nu_s-\nu_i=\vec\gamma$$





a double telecentric system



the entrance pupil is the the image of the limiting aperture into 

aperture stop limits the direction cosines passing from object space
to image space through the optical system

in a certain distance from the image plane a spherical wave is assumed,
the so-called Gaussian reference sphere


\begin{align}
  \beta = \frac{\nu}{\nu'}=\frac{n\sin\alpha}{n'\sin\alpha'}
\end{align} % FIXME steht da nun n oder nicht? IAT 3

the aplanatic surface and ewald sphere are related just by a factor
$f\lambda$

for application of linear systems theory it is necessary that the
imaging conditions are invariant at least over small regions of the
field plane (isoplanatic condition)

The field in the pupil is
\begin{align}
u(\nu)=F\left[U(x)\right]
\end{align}


The field behind the pupil aperture is
\begin{align}
u'(\nu)=h(\nu) u(\nu)
\end{align}

the field in the image plane is obtained by a repeated Fourier
transform with a corresponding scaling of the pupil coordinates
linear mapping between object and image space coordinates $x'=\beta x$

scaling of the spectra $\nu'=$
\begin{align}
U'(x')=\mathcal{F}(h(\nu) u(\nu)) = H(x) \otimes U(x) = \int U(x'') H(x-x'') \textrm{d}x''
\end{align}

the camera can only detect the intensity
\begin{align}
I'(x')=|U'(x')|^2=U'(x')U'^*(x')
\end{align}

the marginal ray starts from an outer field point in the object and
passes through the center of the entrance pupil, which here is in
this double telecentric system is in axial infinity 

in a system, natural vignetting (projection along chief ray in object
and image) should be taken into account with energy apodization
factors

etendue
geometrical flux



The uncoloured beam in \figref{fig:widefield-microscope}~a) represents
rays that start from the intersection $O$ of the optical axis and the
front focal plane of the objective. The objective collects the rays
and collimates them into a beam that is parallel to the optical
axis. After traversing the tube length $f+f_\mathrm{TL}$, the rays are
focused by the detection tube lens TL1 on the intersection $O'$ of its
focal plane and the optical axis. 

The blue beam corresponds to rays that start from an off-axis point
$P$ in the front focal plane of the objective. Behind the objective
the blue beam is a parallel beam. However, the beam is tilted relative
to the optical axis. The tube lens TL1 focuses the blue beam into a
spot at $P'$ on its focal plane.

The objective fulfils the Abbe sine condition -- it is aplanatic. The
microscope forms stigmatic\footnote{An imaging system collects some of
  the rays, that leave an object and directs them towards the
  image. If all rays that leave an object point converge in the
  conjugate image point, then we call the image point stigmatic.}
images of points from the front focal plane in the plane perpendicular
to the optical axis, containing $O'$ and $P'$. The plane with the
images is called intermediate image plane. It is magnified by the
factor $M$:


In our microscope we use an objective with magnification $M=63$. The
focal length of the tube lens is for most Zeiss
microscopes. Therefore the focal length of our objective is
$f=\unit[2.61]{mm}$.

Let's assume we have an opaque sample with just two small
($\diameter<\unit[120]{nm}$) holes with $\unit[2]{\mu m}$ distance
between them.  We put this object into the front focal plane of the
objective and position a camera on $O'$. When illuminating the mirror
from the side opposite to the objective, the camera will show two
spots with $\unit[126]{\mu m}$ distance.

\nomenclature{NA}{Numerical aperture $\textrm{NA}=n\sin\alpha$, with
  refractive index $n$ of immersion medium and acceptance half-angle
  $\alpha$ of the lens}

Note that \figref{fig:widefield-microscope} depicts a \emph{thin-lens
  model of a high numerical aperture objective} that fulfils Abbe's
sine condition. A real objective contains in the order of ten coated
lenses of different glass and crystalline materials. Their curvatures,
positions and materials were all carefully chosen, taking into account
manufacturing tolerances and wavelengths, so that the microscope
behaves as the thin-lens model predicts. Diffraction at the periphery
of the pupil in the back focal plane dictates the resolution, one can
achieve inside of the sample.


It is quite possible that heating to \unit[37]{${}^\circ$C} will ruin
such a high-precision instrument. A related source of aberrations
(departure of design performance) is the refractive index inside of
the specimen. In Appendix~\ref{sec:ray-aberration} we describe a more
complicated model that can predict the effect of embedding the sample
in water (instead of immersion oil with the same refractive index as
the glass).

\subsection{Widefield epifluorescence microscope}
Fluorescence photons are emitted in all directions, independent of the
original illumination direction. Therefore it is possible and
convenient to use the objective for excitation as well as
detection. This mode of microscopy is called epifluorescence (Greek:
$\varepsilon\pi\iota$; on, above).  In this configuration usually only
a small percentage of the excitation light returns due to diffraction
or reflection. This simplifies the separation of fluorescence light
from excitation light.  Furthermore parts of opaque specimen can be
imaged and it is beneficial that the illumination needs to be aligned
only once.

\nomenclature{BFP}{Back focal plane}

The red beam in \figref{fig:widefield-microscope}~c) is a parallel
laser. The excitation tube lens TL2 focuses the beam into the back
focal plane (BFP) of the objective. The beam is reflected at a
dichroic beam splitter (BS). This is a glass plate that has been
coated with dielectric layers. The refractive index, thickness and
sequence of the layers are designed so that the excitation light is
reflected towards the objective. Excitation light, that is scattered
or reflected in the sample and returns through the objective is
reflected towards the light source. However, lower energy fluorescence
light returning from the objective is transmitted towards the
camera. Behind the objective the beam is parallel and illuminates the
specimen. The field of view is the demagnified diameter of the laser
beam before TL2.
\subsubsection*{Non-uniformity due to coherent interference}
Note that tiny dirt particles and coherent interference in laser beams
can produce unwanted non-uniformities in the illumination. As a remedy
the spatial coherence of the laser is sometimes reduced.  Incoherent
light emitting diodes, mercury or xenon arc lamps are often used
instead of lasers. In the latter case a band pass filter selects the
useful part of the spectrum of the excitation lamp upstream of the
dichroic beam splitter.

\subsubsection{Out-of-focus blur}
However, independent of the choice of the light source, the wide field
microscope in epifluorescence configuration exposes many layers of the
sample. This leads to fluorescence of out-of-focus fluorophores.

There are two reasons, why out-of-focus fluorophores give blurred
images. Not even an ideal imaging system -- a device that forms
%% FIXME refer to maxwell or born/wolf
stigmatic images of all the points in one volume in another volume --
would form sharp images on the camera plane. After all, the camera is
just a plane and the object under observation is three dimensional.

Furthermore a microscope is far from being an ideal imaging system. In
a microscope it is not possible to obtain a sharp image of a different
slice of the object by changing the axial position of the camera
behind the tube lens TL1 \citep{Botcherby2007,Botcherby2008a}.
\subsubsection*{Deconvolution}
When a stack of several slices of an object is obtained, it is
possible to suppress the blurred part of each image in all the
others. These algorithms (deconvolution) can improve the perceived
quality of images in some stacks. However, there are two fundamental
problems:

First the \emph{missing cone problem} prevents focusing on a
homogeneous fluorescent plane. Physics dictates that there is always a
gap in the transfer function of the objective when the fluorescence
process is linear and the objective collects only photons from one
half space (see \figref{fig:missing-cone}). Not all spatial
frequencies within the transfer function attenuate with defocus
\citep{Neil1997}.

\begin{figure}[!hbt]
  \centering
  \svginput{1}{missing-cone}
  \caption{Schematic depicting $k_xk_z-$cross sections of the support
    of optical transfer function (see Appendix~\ref{sec:app_hilo}) for
    microscope objectives with different collection angles. {\bf
      left:} Objectives, that only collect light that is directed into
    one half space, have the missing cone problem. There, low spatial
    frequencies do not attenuate with defocus. {\bf right:} Theoretical
    objective with larger collection angle and no missing cone.}
  \label{fig:missing-cone}
\end{figure}

Second, even with ideal detectors there is photon shot noise in the
image. In deconvolution algorithms the image of one slice is improved
by subtracting blurred versions of the other slices. When the blurred
intensity is large, its shot noise is high as well. Subtraction only
increases noise and a faint in-focus image can be severely
deteriorated by the noise of the out-of-focus light.
\subsection{Confocal microscope}


{\bf c)} Confocal
    microscope. A pinhole PH2 is imaged as a diffraction limited spot
    into the specimen. Returning fluorescence light is only detected
    when it passes through an aligned pinhole PH1. This configuration
    rejects light that doesn't originate from the front focal plane
    (green) of the objective.

One way of addressing both problems of the wide field microscope is
depicted in \figref{fig:widefield-microscope}~c). In the confocal
microscope the whole field of view isn't illuminated simultaneously.
The excitation tube lens TL2 collimates the light coming from a
pinhole PH2 and illuminates the full back focal plane of the
objective. In the front focal plane of the objective the red beam then
converges to illuminate the smallest possible single spot. The spot
size is defined by diffraction at periphery of the BFP. However,
out-of-focus fluorophores are still being excited by the hour-glass
shaped illumination.

The eponymous idea of the confocal microscope is to replace the camera
with a pinhole PH1. This pinhole, if aligned carefully to the position
of the image of the focused laser spot, has no influence on the light
detected from in-focus fluorophores. However, an out-of-focus
fluorophore that is defocused by $\Delta z$ towards the objective will
lead to a diverging beam (colorless) at the tube lens and will be
imaged into a point behind the focal plane of the tube lens. The
pinhole only transmits a part of the circle of confusion. Hence
defocused fluorophores contribute less to the sensor signal.

An image of the in-focus specimen is obtained by scanning the pinholes
PH1 and PH2 over the field of view and measuring intensity at each
position individually. The optical removal of out-of-focus light
prevents degradation of the signal by its shot noise and improves the
point-spread function of the objective. The missing cone problem is
fixed and the resolution improved by a factor of two. Note however,
that information about out-of-focus fluorophores is lost which would
be obtained in a wide field microscope with deconvolution. Therefore a
wide field microscope will give better results when a lot is known
about the sample structure and this knowledge is fed into the
deconvolution. E.g.\ the localization of sparse beads of specific size
will be better in a wide field microscope.

The confocal microscope was invented in 1955 \todo{check patent
  citation} \citep{Minsky1961,Minsky1988} to reduce the influence of
scattering effects in neuron samples stained by Golgi's method. This
invention preceded the laser and was unfortunately not put into
practical use for biology until three decades later \citep{Amos1987}.
\subsection{Phototoxicity in conventional microscopes}
When imaging living specimen we should distinguish between useful and
unnecessary excitation. Taking into account the detection capabilities
of objective lenses we should maximize the ratio of in-focus to
out-of-focus fluorescence. The epifluorescent wide field and confocal
microscope surely do not represent an optimum in this regard.

The following chapter \ref{sec:approaches} will introduce other
microscopy techniques that are more considerate of where to deposit
excitation power within the specimen.
\subsection{2-photon laser scanning fluorescence microscopy}
\label{sec:2-photon}
If the laser intensity in the focal spot of a confocal microscope is
sufficiently high, then two infrared photons can be absorbed within
\unit[$\sim 5$]{fs} and excite the same electronic state.

In this regime, the fluorescence emission increases quadratically with
laser intensity. This non-linearity confines the excitation volume to
the vincinity of the focal plane \citep{Denk1990}. Fluorophores
outside of this region are not excited. Therefore this method produces
sectioned images by default and there is no need for a detection
pinhole.

As an additional benefit infrared light is scattered less than visible
light of half the wavelength. This increases penetration depth and
image quality. Photodamage outside of the focal volume is unlikely and
phototoxicity is much lower, compared to the single-photon confocal
microscope, when $z-$stacks are acquired.

However, the phototoxicity within the focal volume is higher and
techniques like ultramicroskopy (section
\ref{sec:light-sheet-microscopy}) with single-photon excitation are
preferable, when low overall phototoxicity is a requirement.

\section{Image detectors in wide field microscopy}
\label{sec:ccd-intro}
\begin{summary}
  Here we describe CCD\nomenclature{CCD}{Charge-coupled devices}
  sensors and their characteristics.
\end{summary}
Charge-coupled devices are semiconductor devices that contain a 2D
grid of capacitors, formed by at least three groups of electrodes
(phases). Cycling the voltage on these electrodes allows to push
charges, which has been accumulated under the capacitors (registers)
into their neighbours. They turned out to be the ideal tool to move
charges, produced by photon absorption in light sensitive diodes,
across the substrate into read out logic.

Forty years of development lead to imaging devices with remarkable
charge transfer efficiency, high quantum efficiency (up to 95\% with
back illumination) and very low dark currents. Until ten years ago the
performance of CCD imagers in the low light regime was limited by the
noise of the read out amplifier (a few electrons per pixel
rms\footnote{root mean square} \todo{rms}).

Since the millennium we have electron multiplying CCD (EMCCD)
\nomenclature{EMCCD}{Electron multiplying charge-coupled devices}
technology, which allows comparably good performance at low photon
numbers \citep{Mackay,Robbins2003} and moderate read out speeds (tens
of MHz). EM-CCDs contain a row of additional registers in front of the
read out circuit. There, one of the three phases is clocked with a
much higher voltage (up to \unit[40]{V}) then is needed purely for
charge transfer ($\unit[\sim6]{V}$). The large electric fields cause
charge carriers to be accelerated to sufficiently high velocities, so
that additional carriers are generated by impact ionization. The
charge multiplication chance per transfer is small ($\sim1\%$) but by
using several hundred registers a substantial gain in the number of
charges can be achieved. In microscopy we usually work with gains of
up to 300. Higher gains are possible but limit the dynamic range.

The charge amplification helps to push the read noise from
$\sim\unit[40]{electrons\ rms}$ to significantly below
$\unit[1]{electron\ rms}$ --- in effect creating a sensor limited only
by the photon noise. However, the multiplicative nature of the gain
leads to a perceived reduction in the quantum efficiency of the sensor
(excess noise factor), i.e. an image with $\unit[100]{photons/pixel}$
without gain will look like the same image at only
$\unit[50]{photons/pixel}$ with EM-gain (see Appendix
\ref{sec:ccd-meas}).


pixel in
ccd ist passiv
cmos ist aktiv

column parallel readout sony exmor

exmor r additionally back illuminated (only works for small sensors)

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "kielhorn_memi"
%%% End: 
