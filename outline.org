
#+OPTIONS: LaTeX:dvipng
#+TITLE: spatio-angular microscopy


#+LaTeX_HEADER: \usepackage{amsmath}
#+LaTeX_HEADER: \usepackage{amssymb}

#+LaTeX_HEADER: \newcommand{\vect}[1]{\mathbf{#1}}
#+LaTeX_HEADER: \renewcommand{\r}{\vect r}
#+LaTeX_HEADER: \renewcommand{\a}{\vect a}
#+LaTeX_HEADER: \newcommand{\s}{\vect s}
#+LaTeX_HEADER: \def\k{\vect k}
#+LaTeX_HEADER: \def\d{\vect d}
#+LaTeX_HEADER: \def\dV{\textrm{d} V}
#+LaTeX_HEADER: \def\e{\vect e}
#+LaTeX_HEADER: \def\f{\vect f}
#+LaTeX_HEADER: \def\c{\vect c}
#+LaTeX_HEADER: \def\x{\vect x}
#+LaTeX_HEADER: \def\y{\vect y}
#+LaTeX_HEADER: \def\z{\vect z}
#+LaTeX_HEADER: \def\q{\vect q}
#+LaTeX_HEADER: \def\p{\vect p}
#+LaTeX_HEADER: \def\l{\vect l}

#+LaTeX_HEADER: \newcommand{\nvect}[1]{\vect{\hat{#1}}}
#+LaTeX_HEADER: %\renewcommand{\i}{\nvect i}
#+LaTeX_HEADER: \newcommand{\vi}{\nvect \i}
#+LaTeX_HEADER: \renewcommand{\[}{\left[}
#+LaTeX_HEADER: \renewcommand{\]}{\right]}
#+LaTeX_HEADER: \renewcommand{\(}{\left(}
#+LaTeX_HEADER: \renewcommand{\)}{\right)}
#+LaTeX_HEADER: \def\hc{\nvect c}
#+LaTeX_HEADER: \def\hs{\nvect s}
#+LaTeX_HEADER: \def\hd{\nvect d}
#+LaTeX_HEADER: \def\hx{\nvect x}
#+LaTeX_HEADER: \def\hy{\nvect y}

#+LaTeX_HEADER: \def\hz{\nvect z}
#+LaTeX_HEADER: \def\n{\nvect n}
#+LaTeX_HEADER: \def\t{\nvect t}
#+LaTeX_HEADER: \def\m{\nvect m}
#+LaTeX_HEADER: \def\vrho{\boldsymbol\rho}
#+LaTeX_HEADER: \def\abs#1{\mathopen| #1 \mathclose|}

#+LaTeX_HEADER: \DeclareMathOperator{\sign}{sign}
#+LaTeX_HEADER: \DeclareMathOperator*{\sinc}{sinc}
#+LaTeX_HEADER: \DeclareMathOperator*{\rect}{rect}


- preface
  - describe my place in project "A preface or foreword deals with the
    genesis, purpose, limitations, and scope of the book and may
    include acknowledgments of indebtedness;
  - stelle zusammenhang mit memi projekt klar
    - erklaert die verwendung des graustufen mikrodisplays
    - vielleicht kann ich hier die vorteile des graustufendisplays
      erwaehen (verminderte gibbs ueberschwinger), obwohl ich den
      tatsaechlichen effekt ja weder vernuenftig theoretisch simuliert
      habe, noch in einer messung nachgewiesen
    - darauf hinweisen, dass ich die holographische methode
      experimentell untersucht habe und auch den dic ansatz fuer
      intensitaetskontrasterzeugung
    - in-vision hat die optische hardware gebaut, fraunhofer das mma,
      die wurmexperimente und das gel wurden in pasteuer entwickelt
  - jedes kapitel erklaeren
  - erklaerung das der source code frei verfuegbar ist und
    dokumentieren, was er beinhaltet
  - danksagung
* introduction
  - an introduction deals with the subject of the book, supplementing
    and introducing the text and indicating a point of view to be
    adopted by the reader. The introduction usually forms a part of
    the text [and the text numbering system]; the preface does not."
** motivation
- levoys plastiksoldat hat den pruefern nicht gefallen, also auf
  mikroskopie konzentrieren
- motivation fuer fluoreszenzmikroskopie
  - spezifisch label, lebende organismen
  - nachteil: ueberschussenergie der fluoreszenzanregung fuehrt zur
    bildung von giftstoffen und damit phototoxizitaet
  - bleaching
- 3 bilder mit c. elegans embryonalentwicklung bei verschiedenen
  anregungsleistungen gegenueberstellen
- moeglicherweise auch optogenetik erwaehnen
  - bin mir nicht sicher ob ich das gegenueber 2photonen gut verkaufen kann
  - m. booth: 2photonen hat breiteres anregungsspektrum,
    einzelphotonenanregung (mit spatio-angular) koennten deshalb
    vorteilhaft fuer multicolor optogenetik experimente sein

** fluorescence and phototoxicity
- molekuelorbitale und viel photophysik (born-oppenheimer, franck-condon) weglassen
*** absorption and emission of light
- stokes shift, triplet state und photobleaching muessen eingefuehrt werden34
- die interessanten sachen aus sauer buch wuerde ich drin lassen
  (erklaerung warum es nur fluorophore von 200 bis 700 nm gibt)
*** depopulation pathways of excited states
- diese formel ist zu komplex: $I_{em}(\r) = Q_E \frac{\sigma
  I_{ill}(\r)}{1+\sigma \tau I_{ill}(\r)} S(\r)$, ich erwaehne sie
  daher nicht
- kasha's rule und energy level diagram mit zeiten
*** photobleaching and phototoxicity
- sauerstoffradikalproduktion durch triplett-triplett annihilation am
  chlorophyll beispiel
- wege wie man bleaching chemisch verhindern kann -- keine dieser
  methoden geht vernuenftig mit lebenden organismen
** conventional microscopes
*** image formation in widefield microscope and the missing cone
   - tubuslaenge und objektiv erklaeren
   - signal haengt linear mit fluorophorkonzentration zusammen
     $I_{em}(\r) \propto I_{ill}(\r) S(\r)$
   - $E(\r) = [S\otimes h_{det}](\r)$
   - $\tilde E(\k) = \tilde S(\k) \tilde h_{det}(\k)$
   - missing cone erwaehnen (bild davon zeigen, nicht herleiten)
   - perhaps cite jerome mertz "introduction to optical microscopy"
   - otf $h_{det}(\k)$ acts as a fourier filter and has no support in
     the missing cone
   - impossible to determine z-position of low-spatial frequency
     sample (e.g. fluorescent plane)
   
*** the confocal microscope
   - strahlengang dem widefield mikroskop gegenueberstellen
   - out of focus light is rejected
   - the missing cone gets filled
   - detectors generally have low quantum efficiency, scanning
     technique
   - keine formeln
*** image formation with structured illumination
   - out of focus light can be computationally removed
   - better quantum efficiency than confocal
   - widefield technique
   - wegen poisson rauschen nur fuer duenne samples gegenueber
     konfokaler mikroskopie vorzuziehen
      - aber: ondrejs spim sim zitieren
*** deconvolution
    - man kennt die eigenschaften des abbildenden systems und kann sie
      innerhalb gewisser grenzen (rauschen) wieder aus dem bild
      rausrechnen
** image detectors
  - fruehe ccd kameras besassen nur einen vorverstaerker und adc und
    liefen mit einer hohen taktrate um gesamte frames auszulesen
    (1-40MHz)
  - dadurch bestimmt der schritt der vorverstaerkung das rauschen (bei
    den in der mikroskopie ueblichen lichtarmen bildern)
  - readnoise wird angegeben in elektronen pro pixel und war bei guten
    ccd mit (1MHz ausgelesen) etwa 6 elektronen pro pixel, d.h. ein
    signal von 100/60*6=10 photonen ginge im rauschen unter
  - durch die einfuehrung von em ccd um die jahrtausendwende gelang es
    die vorverstaerkung erheblich zu verbessern und das readnoise
    deutlich unter einem elektron pro pixel zu druecken
    - 512 register, hohe spannung, wsk elektronen aus lattice zu
      schlagen, jedes pixel geringe verstaerkung insgesamt wird bis zu
      300 gain, multiplikatives rauschen
    - eindruck als ob quanteneffizienz durch em verringert wird
    - fuer viele experimente dennoch besser
    - man kann gain noch mehr erhoehen, dann aber nur noch
      einzelphotonen detektieren, das geht ohne verminderte
      quanteneffizienz
  - in den letzten jahren ist ein weiteres konzept verwirklicht wurden:
    - in scientific cmos hat jede spalte ihren eigenen vorverstaerker
      und adc
    - dadurch kann die taktrate dieser elemente um 3 groessenordnungen
      vermindert werden und man erreicht auch ohne em gain
      ausleserauschen von etwa 1 elektron pro pixel
   
*** characterization of read noise
    - um daten zwischen verschiedenen geraeten zu vergleichen
    - beschreibe mein experiment, wo ich zwei em ccd kameras verglichen habe
    - es reichen wenige bilder einer inhomogenen (aber glatten) lichtverteilung
      - beleuchtungsintensitaet (oder irradianz?) muss konstant sein
        und poissonverteilt (anti-bunching vermeiden)
        - ich benutze fluoreszenzfarbstoff
	- waere es nicht besser, eine led zu benutzen? 
        - halogenlampe macht laut rainer bunching (aber ich habe keine
          referenz dazu gefunden)
      - rand sollte dunkel sein, damit drift keine grossen aenderungen
        hervorruft
    - ich zeige nur die ergebnisse fuer die handelsuebliche kamera,
      weil ich nicht weiss, ob ich daten der ixon ultra verwenden darf
      (ausserdem wuerde das nicht viel helfen)
    - ich erklaere, wie ich vollautomatisch die kameras fuer viele
      verschiedene em gains charakterisiert habe
    - andor basic code kommt in den appendix, falls das selbst jemand
      mit seiner kamera machen will
    - probleme mit dem experiment:
      - im nachhinein hat sich herausgestellt, dass ich zwischen den
        aufnahmen nicht genug gewartet habe, damit sich eine stabile
        em spannung einstellt
      - ausserdem ist bleaching des samples aufgetreten (das macht es
        ein bisschen schwierig, genaue aussagen ueber den excessive
        noise faktor zu geben)
    - code fuer die auswertung habe ich in python geschrieben, damit
      kann jemand, der python/numpy mag einfacher einsteigen (braucht
      kein matlab/dipimage)
    - [Scientific images are more than just pictures]
      - graph snr gegen photonenzahl
      - SNR = (QE S)/sqrt(F_n^2 QE (S + I_b) + (N_r/M)^2)
      - diese formel erklaert, besser als ich es bisher gemacht habe,
        den excessive noise factor F_n
      - S signal, I_b background, QE quantum efficiency, N_r camera
        noise, M em-gain
      - EM gain has a statistical distribution and associated
        variance, which is accounted for by F_n. in a typical EM CCD
        camera F_n=sqrt(2)=1.4
*** em-ccd
    - maximum 37 MHz, clock induced charge, dark current not so
      important (weil ich kurze integrationszeiten brauche)
    - vorteil: hohe quantum efficiency
*** scmos
    - global exposure and noise
    - flash 2.8 vs. 4.0
      - 2.8 doesn't have enough physical trigger outputs
    - up to now: scientific not backside illuminated
    - spatial gain variations
    - kink in transfer function
    - big field of view, fast
    - check for dutch chip
   
    - go through hamamatsu information vs. andor
    - 5 vs. 4 transistoren pro chip

    - sony produziert seit 2007 back illuminated cmos fuer smart
      phones; vorhersagen, dass die auch irgendwann fuer scientific
      applications kommen
    - charakterizierung wird deutlich schwieriger, weil man gain jedes
      pixels messen muss
      - statt ein inhomogenes muster ueber den gesamten chip zu
        senden, muss man viele homogene unterschiedliche intensitaeten
        aufnehmen
* methods of controlling illumination patterns
- ueberblick ueber aktuelle literatur: methoden um unnuetze anregung
  im mikroskop zu verringern
** light sheet fluorescence microscopy
*** light sheet generation with cylindrical lens
- hauptprobleme:
  - schichtdicke haengt mit field of view zusammen
  - sample mount ist eine qual und verhindert es experimente zu
    skalieren (z.b. 96 well plates)
*** light sheet generation using the detection objective
- dunsby oblique plane erwaehnen um die abbildungsprobleme zu erwaehen
- bei index mismatch HILO (denn zum akzeptanzwinkel habe ich ja ein
  experiment)
** scanning techniques for improving light utilization
*** controlled light exposure microscopy
- erklaere, wie sie bei CLEM entscheiden wo wieviel licht hinsoll
- kann nicht so einfach auf widefield uebertragen werden, weil dann
  out of focus beitraege variieren
*** acousto-optic deflectors for fast beam steering
- random access
- sollte das aberration correction paper erwaehen (das ist
  schliesslich viel cooler und martin booth steht drauf, leider haben
  die da nur galvos benutzt)
** non-scanning techniques
*** direct illumination
- micro leds: haben schlechten fill factor und ettendue mismatch
*** intensity modulation
**** programmable array microscope
- erwaehne, dass die technik mit dmd im detektionspfad mit schnellen
  rauscharmen kameras obsolet geworden ist
  - nachteile: 
    - interpolation zwischen beiden kameras notwendig (zerstoert
      poissonannahme der daten, verringert aufloesung)
    - streuung des anregungslichts am slm kann kontrast vermindern
    - ebenso etwaig auftretende fluoreszenz
    - da slm black/white ist, entsteht ein sehr breites pattern in der
      back focal plane
**** light field microscope
- erklaere problem mit phasenraumsampling
- microlenses undo directional integration
- history: 1908 patent lippmann
- hauptproblem: 
  - teure NA des objektivs kann nicht fuer hohe aufloesung genutzt
    werden
  - daher nur fuer beleuchtung sinnvoll einsetzbar
  - unsere methode ist besser als prototyp, wenn man noch nicht weiss,
    wieviel aufloesung man im sample haben will (z.b. kann ich
    strukturierte beleuchtung machen, wenn ich will)
  - je nach anwendungsfall kann LFM vorteile bringen, weil es teile
    des samples gleichzeitig aus verschiedenen richtungen anleuchten
    kann
  - unsere methode kann prinzipiell schneller sein (weil zwei displays
    mit geringerer aufloesung)
  - in cameras: commercial sensor resolution often exceed aberration
    limited resolution, plenoptic camera uses excess sensor resolution
    for extra information about the incoming light
*** temporal focussing
- grating in intermediate image sendet regenbogen in bfp der im sample
  zu einer duennen lichtschicht zusammenlaeuft
*** phase modulation
**** digital holography
- v. emilianis ansatz mit IFTA algorithmus
- 3d lichtfeld generierung
- bei 2 photonen treten staerkere speckle auf
- bisherigen text besser von unserer holographie methode abgrenzen
  (emiliani kontrolliert phase in pupillen ebene, wir in intermediate
  image)
**** generalized phase contrast
- beschreibe technik, braucht konstanten fill factor
- hat besseren durchsatz als andere intensity modulationsmethoden
**** generalized phase contrast with temporal focusing
- sehr vorteilhafte kombination, weil speckle verschmiert werden und
  nur eine ebene aktiviert wird
- bloederweise braucht man einen teuren laser
* the concept of spatio-angular microscopy
** summary
  - hier zeigen wir, wie unser spatio-angulares mikroskop im prinzip
    funktioniert
  - zunaechst motivieren wir diese beleuchtungsart anhand zweier
    beispielhaften, in gewoehnlichen samples oft vorkommenden
    fluorophore verteilungen.
  - dann beschreiben wir entscheidungen bezueglich der anordnung der
    optischen komponenten, die wir bereits frueh in der design phase
    treffen mussten. Ausserdem positionieren wir unsere Methode im
    aktuellen Forschungsfeld zur Beleuchtungskontrolle in
    Mikroskopen. Von allen bisher veroeffentlichten ansaetzen der
    beleuchtungssteuerung in der mikroskopie kommt unserem ansatz das
    lichtfeldmikroskop (levoy) am naechsten. wir erklaeren die
    unterschiede zwischen beiden techniken und gehen auf ihre
    jeweiligen vor- und nachteile ein.  auf eigenheiten und
    beschraenkungen der eingesetzten hardware komponenten gehen wir
    erst in einem spaeteren kapitel ein (ref sec:dev1, sec:mma), weil
    die details der verstaendlichkeit zunaechst abtraeglich waeren.
  - es stellt sich heraus, das eine effektive, die
    phototoxizitaet mindernde nutzung des spatio-angularen mikroskops
    mehr wissen ueber die probe bedarf (fluorophor- und
    brechzahlverteilung) als herkoemmliche mikroskopiemethoden oder
    ein spim mikroskop (ref spim). die computergesteuerte auswahl
    passender beleuchtungsmasks erfordert eine vorhersage, oder
    zumindest das verstaendnis, der dreidimensionalen lichtverteilung
    im objektraum. im letzten teil dieses kapitels beschreiben wir, wie wir
    unser spatio-angulares mikroskop prakisch umsetzen. dabei
    beruehren wir themen der bildverarbeitung.

** motivation
  - Um die grundlegende Idee hinter dem Spatio-Angularen Mikroskop zu
    verstehen, betrachten wir zunaechst die Lichtverteilung im Objekt
    bei einem herkoemmlichen Mikroskop: Abbildung fig:hourglass-all-a
    zeigt schematisch die Seitenansicht von Objektivlinse, Objekt und
    dem Strahlenverlauf des Anregungslichtes in einem konfokalen
    Mikroskop. Ein paralleles Lichtbuendel mit kreisfoermigem
    Querschnitt (in der Darstellung nicht sichtbar) trifft auf die
    Objektivlinse. Die Linse fokussiert das Licht in ihrer Brennebene.
  - Zwischen Linse und Brennebene bilden die Lichtstrahlen einen
    konvergenten Kreiskegel. Wenn Brechzahlvariationen im Objekt
    vernachlaessigbar sind, ist die Lichtverteilung unter der
    Fokusebene aus Symmetriegruenden wieder ein Kegel.  Angenommen,
    wir haben eine schwach absorbierende Probe, die Energie des
    Lichtes entlang der kreisfoermigen Querschnitte innerhalb des
    Kegels bleibt dann konstant. Die Intensitaet innerhalb des Kegels
    ist proportional zur Dichte der Lichtstrahlen in jedem
    kreisfoermigen Querschnitt und steigt daher quadratisch
    an\footnote{Das strahlenoptische Modell gilt in grossen Teilen der
    Darstellung in fig:hourglass-all-a, jedoch nicht ueberall.  Das
    Gesetz von Malus-Lupin besagt, dass die Beschreibung mit
    Lichtstrahlen oder Wellenfronten equivalent sind, solange sich
    Strahlen nicht ueberschneiden (Kaustik) oder (FIXME formeln) ein
    starker Intensitaetsgradient auftritt. Demnach gilt das
    strahlenoptische Modell fast ueberall im Kegel, bis auf einen
    Bereich mit einem Abstand von wenigen Wellenlaengen zum Rand und
    im Fokus selbst. Die wellenoptische Behandlung dieser Bereiche ist
    zwar moeglich, rechentechnisch aber erheblich aufwaendiger als die
    Strahlverfolgung. Deshalb beschraenken wir uns bei der Steuerung
    in unserem Prototypen und in dieser Arbeit ausschliesslich auf das
    strahlentheoretische Modell}.
  - Der fluoreszente Bead (1) im Fokus wuerde demnach deutlich
    staerker angeregt werden, als der Bead (2) ausserhalb der
    Fokusebene. Im konfokalem Fluoreszensmikroskop wird das
    Fluoreszenslicht beider Beads vom Objektiv und
    Detektionstubuslinse in die Zwischenbildebene abgebildet.  Das
    Bild (FIXME Zahlen und Beschriftung ins Bild) des in-focus Beads
    (1) ist dabei scharf, von ihm ausgehendes Fluoreszenslicht wird
    auf einer moeglichst kleinen Flaeche konzentriert --- genau auf
    dem Zentrum des Detektionspinholes.  Der out-of-focus Bead (2)
    erzeugt hingegen nur ein unscharfes Bild. Sein Licht wird ueber
    eine grosse Flaeche verteilt. Zum detektierten Signal des
    konfokalen Mikroskops traegt zwar nur ein verschwindend geringer
    Anteil des vom Out-of-fokus Beads emittierten Lichts bei, mit
    Blick auf die Phototoxizitaet des Systems kann man jedoch sagen,
    dass es besser waere, die Anregung des out-of-fokus Beads von
    vornherein zu unterbinden.
  
  - Das Schema in fig:hourglass-all-b demonstriert, wie der
    Beleuchtungskegel manipuliert werden muesste, damit keine Strahlen
    den out-of-focus Bead treffen. Das zu erwartende Fluoreszensbild
    im Zwischenbild enthaelt nur noch Information vom in-focus Bead.
  - Vom in-focus Bead aus gesehen entspricht die Beleuchtungsaenderung
    einer Einschraenkung der Winkel. Eine derartige Kontrolle kann man
    gut durch eine Maske in der anderen Brennebene des Objektivs (BFP,
    Pupille) ausueben.
  - Damit haben wir gezeigt, dass es sinnvoll und moeglich ist ein
    konfokales Mikroskop mit einer Winkelkontrolle auszustatten. In
    unserem Projekt wollten wir jedoch ein widefield Mikroskop bauen,
    um von der Geschwindigkeit und Quanteneffizienz moderner Kameras
    zu profitieren. Nichtsdestrotz ist ein konfokales Mikroskop mit
    Winkelkontrolle der Beleuchtung ein Ansatz mit Potential und einer
    weiterfuehrenden Untersuchung wuerdig. Siehe \ref{sec:conclusion}
    auf Seite \pageref{sec:conclusion} fuer eine Diskussion, welche
    Methoden man gewinnbringend zu einem derartigen System kombinieren
    koennte.
  - Wir widmen uns nun der Aufgabe, die Winkelkontrolle der
    Beleuchtung in ein widefield Mikroskop zu bringen. Abbildung
    fig:hourglass-all-c zeigt eine Konfiguration des Spezimen
    mit zwei in-focus Beads (5) und (6). Wenn beide gleichzeitig, also
    das gesamte Feld durch eine ausgedehnte Lichtquelle, beleuchtet
    werden, gibt es keine Moeglichkeit die Beleuchtung des
    out-of-focus Beads (7) zu vermeiden. Erst durch eine selektive
    Beleuchtung der in-focus Beads, wie in fig:hourglass-all-d
    dargestellt, hat die Winkelkontrolle wieder einen Einfluss. Ein
    widefield System mit Winkelkontrolle bedarf also gleichzeitig einer
    Maske im Feld. Daher nennen wir unsere Methode spatio-angulare
    Mikroskopie. "Spatial" bezieht sich auf die Beleuchtungskontrolle
    im Feld und "angular" auf die Kontrolle in der Pupille.
  - In Abbildung fig:memi-simple ist der Strahlengang durch
    unseren Prototyp stark vereinfacht dargestellt. Auf der linken
    Seite befindet sich eine ausgedehnte Lichtquelle. Durch die
    telezentrisch angeordneten Linsen $L_1$, $L_2$, $L_3$ und die
    Objektivlinse wird die Lichtquelle in die vordere Fokusebene (F
    fuer Feld) des Objektivs, also in die Probe, abgebildet. Die
    Ettendue (auch Space-Bandwidth product (FIXME check definitions))
    der Lichtquelle muss gross genug sein, sowohl die Pupille P als
    auch das Feld F auszuleuchten.
  - In den Ebenen P' und F' platzieren wir jeweils einen spatialen
    Lichtmodulator, der die Intensitaet des hindurchgelassenen Lichts
    veraendert.
  - Vom Schema in fig:memi-simple koennte man meinen, man koennte eine
    Linse einsparen, wenn der pupil plane SLM in P statt in P'
    platziert werden wuerde. Es gibt drei Gruende warum dies nicht
    moeglich ist oder keine Vorteil bringt:
    - Erstens ist die Pupille in modernen Hochleistungsobjektiven
      nicht zugaenglich\footnote{Dies ist historisch bedingt. Um
      Kompatibilitaet verschiedener Objektive im Objektivrevolver zu
      garantieren, so dass sich Nachfokussieren beim Objektivwechsel
      eruebrigt, wurde die Baulaenge der Objektive festgelegt (bei
      Zeiss sind das 45mm). Heutzutage kann man die Baulaenge ohne
      weiteres mit dem motorisierten Fokus korrigieren und man wuerde
      meinen, dass die Hersteller endlich groessere
      Hochleistungsobjektive produzieren koennten, so dass die Pupille
      zugaenglich wird.}.
    - Zweitens sollte der Detektionspfad fuer das Fluoreszenslicht
      moeglichst wenige optische Komponenten enthalten.
    - Drittens rufen die zwei Masken eine nicht-lineare und daher
      schwer vorhersehbare Filterung der Ortsfrequenzen hervor. Eine
      genaue Betrachtung bedarf die Beruecksichtigung partieller
      spatialer Kohaerenz.
  - Daher haben wir uns entschieden, den focal plane SLM downstream
    vom pupil plane SLM zu platzieren um die beste Qualitaet des focal
    plane SLM im Spezimen zu gewaehrleisten.

  - Diese Aufloesung, mit der wir die Beleuchtung im Feld steuern
    koennen, ist das wesentliche Kriterium, in der sich unser Ansatz
    von Levoy's Lichtfeldmikroskop unterscheidet. Im
    Lichtfeldmikroskop beschraenkt die Dichte der Mikrolinsen die
    Aufloesung erheblich. Zwar ist es im Lichtfeldmikroskop moeglich,
    die Einfallswinkel in allen Feldpositionen unabhaengig zu aendern,
    dies erfordert jedoch einen einzelnen SLM mit sehr vielen Pixeln,
    der nur vergleichsweise langsam angesteuert werden kann. Wir
    setzen zwei deutlich kleinere SLM ein, die wir sehr viel
    schneller--mit etwa 1kHz Bildwiederholrate--ansteuern koennen. Die
    Anzeige von hochaufgeloesten Mustern (Strukturierte Beleuchtung)
    im Feld gibt uns die Moeglichkeit, optische Schnitte der Probe zu
    berechnen und mit unserem Widefield Mikroskop Bilder zu erzeugen,
    die sonst eines konfokalen Mikroskops beduerften. Wir werden
    zeigen, dass die optischen Schnitte besser sind, wenn die
    strukturierte Beleuchtung hohe Aufloesung aufweist.

    

  - PP-SLM kann grauwerte

  - erforschen einen aehnlichen ansatz wie levoy
    - (b) zeigt, wie die einschraenkung der beleuchtungswinkel die
      anregung des out of focus beads verhindert
      - je nach struktur des samples koennte die winkelkontrolle der
        beleuchtung clem auch im widefield mikroskop ermoeglichen
      - denkbar waere beispielsweise mehrere aufnahmen derselben
        feldverteilung mit unterschiedlichen
        winkelverteilungen. etwaige aenderungen im detektierten
        widefield bild wuerden dann den schluss auf out of fokus
        information und damit die korrektur von artefakten zulassen
  - wir beherrschen damit in gewisser weise das lichtfeld
    - verglichen mit levoy koennen wir volle aufloesung erreichen
      (falls keine aberrationen auftreten)
    - polarisation wird nicht kontrolliert
    - wir koennen nicht verschiedene punkte im feld gleichzeitig aus
      verschiedenen winkeln beleuchten
      - das ist aber fuer viele anwendungen nicht unbedingt
        erforderlich
      - ich argumentiere, dass es wichtig ist, hohe aufloesung
        erreichen zu koennen, denn das laesst den weg offen, auch
        hochaufloesende bilder mit unserem mikroskop zu erzeugen
      - vermutlich interessant aber bisher auch noch nicht untersucht
        ist die moeglichkeit hohe aufloesung in der bfp zur erreichen
  - c) zeigt eine sample konfiguration, bei der angular control
    alleine kaum zu einer verminderung des out of focus lichtes fuehrt
    - eine derartige anordnung der fluorophore tritt haeufig in proben
      auf
    - so lange ein grosser in focus bereich in der probe beleuchtet
      wird, haben winkelaenderungen keine auswirkung auf die
      lichtdosis, die der out of focus bead bekommt
    - mit dem focal plane slm sind wir in der lage, den in focus
      bereich in kleinere bereiche zu teilen (d) und nacheinander mit
      entsprechend optimierten winkeln zu beleuchten, die den out of
      focus bead nicht anregen
    - selbst bei finitem ausleserauschen macht dieser ansatz sinn, man
      kann ja einfach die unbeleuchteten stellen im bild null setzen
      und vermindert somit nicht das SNR wenn mehrere bilder
      zusammengefuegt werden (erst dachte ich das geht nur mit
      modernen kameras)
  - strukurierte beleuchtung in unserem system weitet die genutzten
    winkel erheblich auf
    - bei groben gittern kommt es zu vielen hoeheren ordnungen, weil
      der focal plane slm nur schwarz/weiss darstellt
    - die darstellung eines gitters erfolgt nur in einer orientierung
      mit optimalen kontrast (weil polarisation in unserem prototypen
      nicht gedreht werden kann)
    - d.h. es gibt eine ideale konfiguration fuer strukturierte
      beleuchtung, die fuer optisches scheiden verwendet werden kann
      aber nicht sonderlich fuer aufloesungserhoehung taugt
 
** An imaging protocol for spatio-angular illumination control 
*** Beschreibung eines biologischen Samples
- Jetzt stellen wir dar, wie man mit dem spatio-angularen Mikroskop
  eine schonende, kaum phototoxische Zeitrafferaufnahme eines sich
  entwickelnden C. elegans Embryo herstellen koennte. Letztendlich
  gelang waehrend dieser Arbeit nicht, die Entwicklung eines Embryos
  aufzunehmen. Problematisch ist die Transmission des Gesamtsystems
  und die Zeit mit der neue Bilder in ein Display geladen werden
  koennen. Trotzdem hielten wir stets dieses Beispiel bei unseren
  Untersuchungen und Methodenentwicklung im Auge.
- Die Embryos sind vom Strain AZ212. Sie sind genetisch veraendert, so
  dass die Mutter Histone mit eGFP (enhanced green fluorescent
  protein, lambda_ex=490nm) bildet (FIXME references paris). Die
  Mutter hinterlaesst eine ausreichende Menge dieser Histone im
  Zellinneren des Embryo, denn dieser kann bis zu einem spaeteren
  Entwicklungsstadium keine eigenen bilden. Histone werden waehrend
  der Zellteilungen in das Chromatin eingebaut. D.h. die Zellkerne
  dieses Strains fluoreszieren gruen.
- Der Embryo entwickelt sich in den ersten Stunden innerhalb des
  konstanten Volumen seines ovalen Ei's mit Achsen zwischen 40 bis
  60um, kann also kontinuierlich bei gleicher Vergroesserung
  untersucht werden. Zellteilungen erfolgen alle paar Minuten. Es
  reicht aus, jede Minute einen Stack mit 20 Schichten im Abstand von
  1 um aufzunehmen, um das Schicksal der Zellen verfolgen zu koennen.
*** Preparation des Embryo samples
- Fuer eine Beobachtung, wird ein Wurm aufgeschnitten und die Embryos
  auf eine Agaroseplatte gelegt. Von diesen waehlt der Experimentator
  einen jungen Embryo aus, der sich noch nicht geteilt hat. Dies kann
  man schonend mit einem DIC (differential interfernce contrast) oder
  Mikroskop feststellen.
- Ein erster Stack mit strukturierter Beleuchtung dient dazu, den
  Nukleus und das Ei zu lokalisieren. Da das Ei in der Agarose fixiert
  ist und sich die Zellen nur langsam im Embryo bewegen, kann die
  Nukleusposition zum naechsten Zeitpunkt mit einer geringeren Dosis
  bestimmt werden, indem ein Bereich um die urspruengliche Position
  des Nukleus beleuchtet wird. Auf diese Weise kann die Entwicklung
  ueber einige Zellteilungen schonend verfolgt werden. Die Nuklei
  werden waehrend der Embryonalentwicklung kleiner und ordnen sich
  dichter aneinander. Nach einer Weile wird es dann vorteilhaft,
  angulare Beleuchtung zu nutzen um die Anregung von Nuklei, die
  Ausserhalb des Fokus liegen, zu vermeiden.

  - explain on the example of an embryo or neuron how an experiment
    might be conducted 
  - erster stack strukturiert beleuchten
  - nuklei finden
  - irgendwelche masken fuer focal plane SLM und pupil plane SLM
    finden um bilder von in-focus nuklei zu machen

***  Sectioning through structured illumination
- Strukturierte Beleuchtung ist eine hilfreiche Methode, um das
  Missing Cone Problem im Weitfeld Mikroskop zu
  verhindern. Moeglicherweise sind normale, ungeschnittene
  Weitfeldbilder gerade noch ausreichend, um die Ausgangsposition im
  Embryo zu bestimmen. Fuer unsere spatio-angulare Methode ist das
  Wissen ueber die genaue Fluorophorverteilung jedoch sehr wichtig und
  haben unser Mikroskop so gebaut, dass wir optische Schnitte
  anfertigen koennen.
- Wir verglichen Strukturierte Beleuchtung mit konventioneller
  max--min Rekonstruktion bei LED- und Laserbeleuchtung. Die LED
  Beleuchtung fuehrte zu guten optischen Schnitten, die Rekonstruktion
  mit Laserbeleuchtung enthielt jedoch Rekonstruktionsartefakte.
- (FIXME in appendix) In einem ersten Entwicklungsschritt, bevor
  In-Vision uns den Prototyp fuer das spatio-angulare Mikroskop zur
  Verfuegung stellte, setzten wir einen SLM in die
  Zwischenbildebene. Auf dem SLM wurden vier Streifenmuster angezeigt
  und Wir verglichen einen 70mW 473nm DPSS laser mit 470nm
  LED Beleuchtung (CoolLED).
- Deshalb entschieden wir uns HiLo zu implementieren (siehe Appendix
  FIXME). Mit diesem Algorithmus gelingen uns artefaktfreie optische
  Schnitte, unabhaengig von der Beleuchtungskonfiguration. Ein
  weiterer Vorteil von HiLo ist, dass nur zwei Bilder pro Slice
  benoetigt werden.

   - describe non-robustness of the typical max-min method
   - wir haben artefakte in der max-min rekonstruktion beobachtet,
     wenn wir ein grobes streifenmuster (8 forthdd slm pixel periode)
     mit laser beleuchtet haben
     - irgendwann hat rainer das erklaert aber ich kann mich nicht
       mehr dran erinnern aber es waere cool, wenn ich die story
       bringen koennte
     - grobes gitter heisst im amplitudenbild: einige ordnungen (nicht
       nur 3) gehen durch die bfp
     - irgendwie kam es dadurch im intensitaetsbild zu einigen hoehere
       ordnungstermen
     - bei LED (extended source) werden die weggemittelt, bei laser
       nicht
   - bei verwendung von LED beleuchtung und groben gittern sind keine
     artefakte sichtbar

    - hilo braucht zum einen nur zwei bilder und ist damit schneller
    - zum anderen treten auch bei laserbeleuchtung keine artefakte auf
      (obwohl man fuer hilo schon besser mit nur 3 ordnungen
      beleuchtet, um den crosstalk zu minimieren)
    - refer to appendix for a thorough description, comparison and
      discussion of the different methods
    - ein bisschen kopfzerbrechen bereitet mir noch der bias
      - im paper habe ich das nicht verstanden [2011 mertz Optically
        sectioned in vivo imaging with speckle illumination HiLo
        microscopy]
      - aber ich habe ihr java imagej plugin decompiliert bekommen und
        koennte versuchen ihre implementierung zu verstehen
        (andererseits ist mir das jetzt ziemlich egal)
      - unter equation 10: The first two terms are variance
        contributions of shot noise. Filtering has the effect of
        reducing noise variance and is taken into account with the
        integral term. This bias must thus be subtracted from sigma^2
        prior to the evaluation of C. We have also not considered the
        effects of pixelation in the CCD camera. If the pixel size is
        non-negligible ..

*** Computermodell zur Integration von a-priori Wissen ueber die biologischen Begebenheiten  
- Fuer unser biologisches Beispielsystem, dem C. elegans Embryo,
  entschieden wir uns, die einzelnen Nuklei in einem Stack durch
  Kugeln zu repraesentieren. Eine einzelne Zeitrafferaufnahme der
  Fluorophorkonzentration koennte als in eine Menge von Kugelzentren
  und Radii repraesentiert werden. Waehrend der Beobachtung wuerden
  sich die Mittelpunkte der Kugeln langsam, mit Geschwindigkeiten
  entlang eines Wachstumsvektorfeldes verschieben. Eine Zellteilung
  kuendigt sich durch Aenderung der Fluorophorverteilung innerhalb der
  Kugel an. Dann koennten im naechsten Zeitschritt zwei Kugeln an die
  Bilddaten gefittet werden.
- Wir haben nur einen einfachen Algorithmus implementiert (FIXME
  difference of gaussians und radiusermittlung blob paper), um
  Testdaten aus Zeitrafferaufnahmen aus einem konfokalem Mikroskop zu
  gewinnen. Einer unserer Projektpartner (FIXME ref Jean-Yves) hat ein
  umfangreiches Plugin fuer ImageJ entwickelt, dass aus konfokalen
  Zeitrafferaufnahmen den Baum der Zellteilungen rekonstruiert (FIXME
  Teilungsbaum klingt komisch get screenshot).
- Bevor unser Mikroskop fuer das biologische Problem eingesetzt werden
  kann, muss das Computermodell so erweitert werden, dass es robust
  die Bewegung der Nuklei verfolgen kann und beispielsweise nicht
  einen Nukleus uebersieht. Die Kugelzentren und Radii einer
  Zeitrafferaufnahme koennen zusammen mit dem geschaetzten Vektorfeld
  der Wachstumsgeschwindigkeiten und einer Texturanalyse der
  Bildinformationen innerhalb der Nuklei eine Prognose fuer die
  naechste Belichtung abgeben.
- Ein derartiges Computerprogramm wurde noch nicht entwickelt, wir
  gehen im Folgenden aber davon aus, dass eine Prognose fuer die
  naechste Aufnahme zur Verfuegung steht und untersuchen wie wir
  daraus Masken fuer focal plane und pupil plane SLM ermitteln
  koennen. In unseren Experimenten haben wir den Embryo durch eine
  dreidimensionale Verteilung von 2 um grossen Beads in Agarose
  simuliert.
*** Beleuchtungsoptimierung mittels Raytracer
- Wir beschreiben nun eine naheliegende Methode, um beide
  Beleuchtungsmasken zu ermitteln. Zunaechst definieren wir Masken
  fuer den focal plane SLM:
- Wir koennen aus der vorhergesagten Kugelverteilung ermitteln, welche
  Nuclei nahe der aktuellen Fokusposition sitzen, indem wir das
  Kugelmodell mit einer der fokusebene entsprechenden, ebenen Flaeche
  schneiden. Mit dem focal plane SLM wollen wir die angeschnittenen
  in-focus Nuklei einzeln und nacheinander beleuchten. D.h. jede der
  Masken fuer den focal plane SLM enthaelt zunaechst nur eine Scheibe,
  die einen Nukleus abdeckt.
- Ausgehend von einer derartigen Maske, koennen wir ermitteln, welche
  Winkel den entsprechenden Zielnukleus beleuchten koennen, ohne die
  Nuklei ausserhalb der Fokusebene zu treffen.
- Wie wir bereits zu Beginn des Kapitels erlaeutert haben, genuegt uns
  eine strahlenoptische Betrachtung der Lichtverteilung innerhalb des
  Samples. 
- Wir verbinden Strahlen von der Peripherie eines out of focus Nukleus
  mit dem in-focus Zielpunkt. Die Strahlen bilden einen
  Kreiskegel. Wir berechnen die Brechung dieser Strahlen durch die
  Objektivlinse und bestimmen ihre Schnittpunkte mit der Pupille. Die
  entstehende Figure ist immer ein geringfuegig deformierter Kreis und
  bereits sieben Strahlen koennen das Gebilde gut repraesentieren. Wir
  fuehren diese Projektion fuer jeden out of focus Nukleus und auch
  fuer einige in-focus Zielpunkte aus. Dies ergibt eine Maske in der
  Pupille, die wir mit dem pupil plane SLM anzeigen koennen.
- Leider sind die exakten Konstruktionsparameter von
  Hochleistungsobjektivlinsen nicht oeffentlich zugaenglich. In (FIXME
  ref appendix und hauptteil) zeigen wir, wie wir die Strahlen
  trotzdem durch das Objektiv verfolgen koennen. Wir verwenden ein
  einfaches Modell, dass nur Fokuslaenge, Immersionsbrechzahl und
  numerischer Apertur verwendet. Zusaetzlich haben wir dieses Modell
  weiterentwickelt, um den Einfluss einer nicht brechzahlangepassten
  Einbettung zu beruecksichtigen. Hier wollen wir jedoch gleich
  klarstellen, dass fuer die Bildgebung von Embryos auf jeden Fall
  kein Oelobjektiv, sondern eins mit passender Immersion angewendet
  werden sollte. Nur damit kann gute Bildqualitaet bis 20 um tief in
  das Sample gewaehrleistet werden.

   - das modell der strahlenoptik ist ausreichend:
     - der focal plane slm fungiert als fourier filter fuer den pupil
       slm
     - wenn der focal plane slm licht nur durch einen kleinen bereich
       hindurchlaesst (wenige pixel) funktioniert zum einen die
       winkelbeleuchtung kaum mehr, weil das licht durch beugung an
       den scharfkantigen focal plane slm features ueber die gesamte
       back focal plane verteilt wird 
     - zum anderen wird sehr wenig licht durch das gesamtsystem
       hindurchgelassen. man koennte auch nur kleine punkte im objekt
       beleuchten und braeuchte viele einzelne teilbilder um ein
       gesamtbild zusammenzusetzen (aber: neuron schnitt)
     - angenommen uns reichen eine scheibe mit 3 um aufloesung im
       objekt, das entspricht beim verwendeten objektiv einem anteil
       von ...% der pupille
     - die optimierung aehnelt grundsaetzlich der aufgabe der
       bestrahlungsberechnung (FIXME was ist das richtige wort) in der
       medizinischen tumortherapie mit ionisierender strahlung (gamma
       oder roentgen)
   - braucht man um die offenen winkel zu bestimmen
   - skew rays and realtime feedback are necessary to make the
     raytracer useful during image acquisition

   - aplanatic model for microscope objective, weil hersteller ja
     nicht ihre design parameter freigeben und ich trotzdem den
     einfluss von non-index matched embedding kennen muss
*** Ausblick und vergleich mit Radiotherapie     
- Unser Ansatz zur Beleuchtungsoptimierung ist noch ausbaufaehig. Bei
  der Auswahl, der Maske fuer das focal plane SLM sollte deutlich mehr
  Information ueber das Sample beruecksichtigt werden. Beispielsweise
  koennten nahe beieinander liegende Nuclei gleichzeitig beleuchtet
  werden. Im Extremfall koennte ein highly inclined beam (HILO) eine
  Schicht des gesamten Embryos schneiden. Diese Verbesserung
  vergroessern jedoch den Suchraum erheblich und die Algorithmen
  wuerden vermutlich deutlich aufwaendiger zu Programmieren sein.
- Weiterhin gibt es interessante Spezimen, die man nicht gut durch
  Kugeln repraesentieren kann (z.B. Neuronen). Fuer diesen Fall haben
  wir einen Raytracing Algorithmus begonnen, der ohne ein auf
  analytischen Formen basierenden Modell auskommt. Dabei wird die
  dreidimensionale Fluorphorverteilung direkt als dreidimensionales
  Volumen gespeichert. Dieses Verfahren ist sehr rechenintensiv, kann
  aber gut auf modernen GPUs implementiert werden. In (FIXME ref
  hauptteil und appendix) erklaeren wir den entsprechenden Code.
- Das von uns bearbeitete Problem hat viele Ueberschneidungen mit
  medizinischer Tumortherapie. In einem weiteren Schritt sollten
  entsprechende Algorithmen in unserem System getestet werden.
* device 1: prototype for spatio-angular illumination
** summary 
   - Im vorhergehende Kapitel haben wir das dem spatio-angularen
     Mikroskop zugrundliegende Konzept dargestellt. Hier gehen wir auf
     zusaetzliche Details ein, die fuer die praktische Implementierung
     wichtig sind. Unter anderem die Eigenschaften der beiden
     verwendeten Displays, elektronische Synchronisation der
     verschiedenen Komponenten und einem Algorithmus, um das
     Koordinatensystem der Kamerapixel und der Pixel des focal plane
     SLM ineinander zu transformieren.

   - Das pupil plane SLM wurde durch unseren Partner Fraunhofer IPMS
     waehrend des Projekts neu entwickelt.  Daher widmen wir uns diesem
     Subsystem im Kapitel (FIXME) naeher.

** optical components
 - Bisher haben wir den Strahlengang nur fuer Transmissionsdisplays
   gezeigt (in fig:memi-simple). Solche SLM haben in Praxis aber nur
   sehr geringe Transmission und deshalb verwenden wir in unserem
   System reflektive Displays. 

 - fig:memi-real zeigt schematisch den entsprechend angepassten
   Strahlengang.  Unten links strahlt die Lichtquelle in das
   System. Die Optik ist farbkorrigiert fuer Wellenlaengen im Bereich von 400 bis 700nm.
   Das System beleuchtet nacheinander den pupil plane
   SLM---den vom Fraunhofer entwickelten
   Graustufen-Mikrospiegelarray---und den focal plane SLM, ein
   kommerzielles liquid crystal on silicon Display.
  
   (Notiz: Ich habe mit Prof fuer Mustererkennung gesprochen und bin
   jetzt motiviert, einen Raytracer zu schreiben, um die Qualitaet der
   beiden Erzeugten masken zu evaluieren. Prinzipiell muss ich von
   jeden durchlaessigen Punkt der Pupille alle beleuchteten Punkte im
   Feld durchtracen. Als Ergebnis waere die Anzahl Strahlen innerhalb
   von in-fokus Objekten geteilt durch die Anzahl Strahlen, die
   Out-of-focus Objekte treffen nuetzlich.  D.h. ich brauche
   ueberhaupt nichts neues Programmieren. Der Code existiert bereits.
   Fuer jeden in-focus Punkt erzeuge ich eine Maske. Ich brauche eine
   gute Heuristik, um Punkte mit aehnlichen Masken zusammenzufassen. )

  
*** The illumination system
 - Wenn wir einen Laser benutzen, dann senden wir den parallelen
   Strahl zunaechst durch ein Mikrolinsenarray. In der Fokusebene nach
   dem Array befindet sich hinter jeder Linse ein Spot. Das
   Mikrolinsenarray rotiert, so dass diese Spots waehrend einer
   Belichtungszeit der Kamera moeglichst viele Positionen abdecken.
   Durch diese Vorgehensweise koennen wir das Laserlicht, das generell
   hohe oertliche Kohaerenz---also eine geringe Etendue---aufweist, an
   die Etendue der nachfolgenden Optik anpassen. Mikrolinsen mit
   kuerzerer Fokuslaenge fuehren zu groesserer Etendue.

 - Durch mehrfache Reflexion in einem Lichttunnel\footnote{Der Tunnel
   (rod integration system, light pipe, D8_2_v2 is a good document)
   hat einen quadratischen Querschnitt. priv. comm. mit Prof. Herbert
   Gross: "Wenn mit dem Querschnitt die Flaeche parkettiert werden
   kann, dann eignet sich der Tunnel zum Homogenisieren des Lichts".}
   erzeugen wir eine homogene Lichtverteilung in F'''.
   
   (FIXME warum hat invision nicht zwei mikrolinsenarrays
   hintereinander gesetzt?, wieviel licht wird im tunnel absorbiert?)
 
 - druecke winkel in seconds of arc aus? (FIXME einheit nachschauen)

 - Fuer Experimente mit einer LED Lichtquelle, haben wir diese immer
   in der Naehe von F''' platziert. Wir platzieren die Oberflaeche der
   LED absichtlich ausserhalb von F''', so dass ihre Details nicht im
   Sample sichtbar sind. LEDs sind Lambertstrahler und strahlen Licht
   in den vollen Halbraum. Eine Lichtemittierende Flaeche mit einigen
   10um reichen demnach aus um die Etendue von Mikroobjektiven zu
   fuellen. Die Auswahl brauchbarer LEDs ist schwierig, den die
   Datenblaetter enthalten selten Angaben ueber die strahlende
   Flaeche. Bei 3W LEDs haben wir einige mm gemessen. Fuer hoechste
   Intensitaet im Sample ist es daher besser, LEDs mit geringer
   Gesamtleistung und kleiner strahlender Flaeche zu verwenden. Diese
   lassen sich dann besser Kuehlen und bei hoeheren Strom betreiben.


 - beschreibe alles mit usb forthdd display, erwaehne vorteile von
   graphikkarte+ dvi lcos und schreibe details in appendix (zum
   beispiel die exakten Brennweiten der Linsen)
- variable tubuslinse 
- schematic mit lichttunnel
** electronics
- z-stage, camera, die zwei displays und laser muessen aufeinander
  abgestimmt werden
** lcos
   - pixel pitch 13.62 um (FIXME check) 
   - fill factor 92%
   - size of sxga display 17.43 mm *13.95 mm = 243.15 mm^2 
   - etendue eps= pi A/(4 F^2)= 18.6mm^2/sr at F/3.2  (FIX1ME figure this out)
     - rhs/f^2 = 17.43*13.95*%pi/4 = 190.97
     - f = sqrt(190.97/18.6) = 3.2
     - mccullum 2008 SID_ME_Jena slide talks about 33.15mm^2/sr
       - they also talk about polarization recycling gaining 40% light
         efficiency
     - in microscope: eps = pi/4 * (D * NA)^2
       - example for my objective with 400um field of view eps=0.27
         mm^2/sr:
#+begin_example
eps:%pi/4 * (D * NA)^2;
D:25/63;
NA:1.47;
eps,numer;
#+end_example 

   - charge balancing maintenance routine (ref The use of LCoS microdisplay)
** mapping
- beschreibe vermessung der koordinatensysteme zwischen focal plane
  slm und kamera
- fuer pupil plane slm habe ich leider keine vollstaendige methode,
  ich zentriere den pupil plane slm auf den ring eines
  phasenobjektivs, kann aber die azimuthale rotation nicht vermessen
  - in erster naeherung sind ja beide displays ziemlich genau aliniert
  - aber ich hatte immer gehofft, eine praezise vermessung ginge mit
    spiegel als sample und einer bertrand linse -- da bin ich aber nie
    dazu gekommen (hauptsaechlich weil ich nie einen
    halbdurchlaessigen spiegel statt dichroic hatte, wenn mal alles
    funktioniert hat)
   
* optimization of the spatio-angular illumination patterns   
- erklaere wie ich schrittweise zu meiner optimierungsmethode gekommen
  bin
- erst raytracing von bfp ins sample (weil die strahlablenkung am
  objektiv dann einfacher auszurechnen geht)
- dann hat man aber shot noise bekommen, deshalb habe ich dann
  rueckwaerts vom sample in die backfocal plane getraced
- weil ich als sample kugeln angenommen habe, konnte ich die anzahl
  der strahlen erheblich vermindern (pro nukleus einen von strahl von
  der mitte und 7 von der peripherie oder so)
- spaeter habe ich das modell dann soweit erweitert, dass auch der
  einfluss von nicht index-matched embedding beruecksichtigt wird

- als diskussion bleibt, dass die optimierungsmoeglichkeiten noch
  lange nicht ausgereizt sind. wenn zwei nuklei nahe beieinander
  liegen, macht es vielleicht sinn, sie gleichzeitig zu beleuchten
  - wenn man sowas auch mit beruecksichtigen will, wird der suchraum
    ziemlich gross
  - ich habe zwar angefangen mich mit A*-search und so zu
    beschaeftigen aber habe da nie weitergemacht, weil das geraet ja
    erstmal laufen musste

** more on the raytracer
   - ein problem mit meinem text war, dass ich die sinus bedingung
     nicht richtig verstanden und beschrieben hatte, hier sind die
     wichtigsten dinge aus prof. gross vorlesung (nur wenig davon kann
     ich einbauen, ich glaube das beste ist die energieerhaltung und
     dass feldpunkte scharf abgebildet werden)
   - aplanatic model for microscope objective
     - exact design parameters of objectives are often not available
     - aplanatic correction:
       - find prof gross reference
       - one optimization goal for a microscope objective is to
         minimize offence against sine condition
       - typical grid distortions are in the range of 1e-3
       - sine condition:
	 - pupil has spherical shape
	 - imaging of small isoplanatic field patches around the axis
           without linear sagittal coma
         - conservation of energy
         - linear representation of spatial frequencies in the pupil
         - same focal length for all angles (focal length normally is
           only defined for infinitesimal small rays)
       - spherical aberration correction
	 - coma completely corrected
    - an dem raytracer ist wichtig, dass ich damit den einfluss von
      non-index matched embedding auf den strahlenverlauf auch ohne
      genaue kenntnis der designparameter des objektivs bestimmen kann
      - das wird wichtig, wenn man unser system praktisch fuer hilo
        (highly inclined ...)  einsetzen will (z.b. embryo in agarose
        mit oelobjektiv), obwohl ich der mittlerweile der meinung bin,
        dass man dann ein wasserobjektiv nehmen sollte
** opencl ansatz
* mma as an intensity modulator
  - mma kontrolliert nur die phasen, wir wollen aber die intensitaet
    modulieren
  - give an estimate of the ettendue that the microscope system can
    cope with

  - description of the mma device (von florians spie paper)
    - consists of 256x256 mirrors with a pitch of 16um
    - each mirror hangs on two thin hinges and can be tilted by up to
      2 degree by electrostatic fields, corresponding to out-of-plane
      deflections of pm 250nm
    - cmos circuitry below each mirror are able to maintain a constant
      tilt for hundreds of milliseconds, while a control board can set
      new analogue voltages for each mirror with an accuracy of
      lambda/100 of the mirror actuation
    - can achieve frame rates of up to 1kHz and duty cylces of up to
      50% (but not at this high framerate)

    - erklaere, die elektroden
** approach using a fourier filter
*** theory
    - ich will die formeln hinschreiben und ein bild zeigen, wie die
      spiegel klappen
    - anhand der formeln kann man dann das fourierbild diskutieren
      - hier waere es gut wenn ich verstehen wuerde warum fraunhofer
        damals das symmetrische fourier pattern einem ordentlichen
        balzed grating vorgezogen hat (das entsprechende patent "1995
        Digital micro-mirror based image simulation system" war aber
        so umfangreich, dass ich den punkt nicht gefunden habe)
    - phase distribution in mma plane: $\sum_\p [(\exp(i \k(p_x,p_y)
      \x) \rect(x,y))\otimes \delta(x-p_x\Delta x, y-p_y\Delta y)]$
    - its fourier transform: $\sinc(k_x-k(p_x,p_y)) \exp(i\k(p_x\Delta
      x,p_y \Delta y))$
    - every other line is tilted in the opposite direction:
       - $I_1(x,y)=e^{+i\k_0\x}\rect(x)\otimes\sum_p\delta(x-p\Delta x)$
       - $I_2(x,y)=e^{-i\k_0\x}\rect(x)\otimes\sum_p\delta(x-p\Delta x)$
    - $I_1(x,y) (\rect(y)\otimes\sum\textrm{every second row})+I_2(x,y) (\rect(y)\otimes\sum\textrm{every second row, shifted by one})$
    - fourier aperture makes response non-linear
    - intensity for single laser $\propto \sinc^2(\textrm{deflection})$
    - point to mehta, sheppard for treatment of partial coherent case
      (extended illumination source)
    - point to fraunhofer publications
** approach using a shearing interferometer
- erklaere dass man bei verwendung des interferometers eine hoehere
  ettendue erwarten kann
*** theory
    - am besten waere, wenn ich eine referenz auf das betroffene
      patent habe (rainer oder kai fragen)
    - point to sheppard
    - refer to experiment in appendix
*** conclusion
- beschreibe resultate des experiments
- grauwerte waren sichtbar, jedoch nicht so gut, wie erhofft
- piston spiegel bewegung ist notwendig fuer guten kontrast, bedarf
  kleinere nomarski prismen und kann deshalb hoehere ettendue
  erreichen (als torsion mirrors)

* device 2: holographic approach
  - beschreibung der methode: stelle phasen gitter in intermediate
    image dar. gitterkonstante und richtung steuert den
    beleuchtungswinkel. gitterkontrast die intensitaet
  - erlaeutere, dass auch strukturierte beleuchtung moeglich sein sollte
  - vorteile:
    - nur ein display, keine triggerung und weniger optik notwendig
      (wenn das display gut ist, bei holoeye braucht man fuer gut
      performance vermutlich schon auf einem kurzen puls, wenn
      fluessigkristalle sich stabilisiert haben)
  - nachteile: 
    - erlaubt nur kleine ettendue (laser beleuchtung oder wirklich
      kleine extended source ist notwendig)
    - holoeye phasendisplay hat schlechte qualitaet (zum an und
      ausschalten funktioniert es aber an graustufen glaube ich nicht
      so recht)
* experimental results with spatio-angular microscope (device 1)
** angular acceptance for different immersion media
- volles feld beleuchtet mit kleinen fenster vom pupil plane slm
- damit kann ein bild der pupillenebene des oelobjektivs ermittelt werden
- oder ein bild des akzeptanzwinkels, wenn embeddingmedium kleine
  brechzahl als immersion
** sectioning by structured illumination with the focal plane SLM
- zeige bead images mit strukturierter beleuchtung und max-min
  rekonstruktion (meine bilder haben die streifenartefakte, um die
  position der beads zu finden ist das okay)
** illuminating a single bead within 3d distribution with various angles 
- nachdem ich die dreidimensionale position der beads bestimmt habe,
  wollte ich sie beleuchten -- vermutlich hat sich der mma da manchmal
  abgeschalten, anders kann ich mir nicht erklaeren, dass die
  differenz der bilder nicht unterschiedliche background fluorescence
  zeigt
- ich habe aufnahmen, die ich waehrend der viva gezeigt habe
** bleaching fluorescent gel
- zumindest das experiment hat funktioniert
* discussion
- zuerst habe ich dvi lcos mit mma verbaut, das hat leider nur
  gelegntlich funktioniert
- dann habe ich usb lcos eingesetzt, damit geht es immer, ist aber
  langsamer und deutlich weniger nuetzlich zum experimentieren
- ausserdem ist die ettendue des beleuchtungssystems arg
  eingeschraenkt mit einem 63x objektiv (NA=1.47) wird nur ein feld
  mit 40 um durchmesser beleuchtet
- deshalb untersuchten wir einen anderen weg zur kontrasterzeugung und
  lernten dabei dass ein interferometrischer ansatz sehr wohl geeignet
  ist, die ettendue zu erhoehen
  - einschraenkungen in der realisierbaren optik (freier durchmesser
    der nomarski prismen) fuehrte zu nicht ganz ueberzeugenden bildern
  - ein piston mma wuerde zu deutlich besseren ergebnisse fuehren
- ein weiterer ansatz fuer spatio-angular beleuchtung wurde mit einer
  holographischen methode verfolgt
  - dabei lernten wir dass die qualitaet des verwendeten
    phasenmodulators zu wuenschen uebrig laesst
  - einfacherer ansatz mit nur einem display, erfordert daher weniger
    optik und elektronik
  - loest jedoch nicht das problem geringer ettendue (die moegliche
    ettendue muss ich mir genauer ueberlegen, sie haengt mit der
    anzahl der pixel des displays und den grating konstanten zusammen,
    die dargestellt werden koennen, da das system off-axis betrieben
    werden muss, wird die ettendue geviertelt)
- Im Nachhinein muss man sagen, dass es Zielfuehrender gewesen
    waere, und unsere Aufgabe erheblich vereinfacht haette, wenn wir
    beide SLM vom gleichen Typ verwendet haetten. Es handelte sich
    aber um einen Prototypen und er war in den ersten Jahr des
    Projektes noch nicht verfuegbar. Das Projekt wird von Pasteur und
    Fraunhofer, diesmal unter Verwendung zweier ihrere SLM,
    weitergefuehrt. 
  - Leider wird dieser Ansatz unsereserachtens nicht das wesentliche
    Problem der kleinen Ettendue bereinigen und der neue Prototyp wird
    noch immer nicht die interessantesten Experimente erlauben. Es ist
    ganz einfach so, dass es einfacher waere, ein biologisch
    Relevantes Experiment zu designen, wenn das Beleuchtungssystem
    auch die volle Ettendue heutiger Mikroskopobjektive ausschoepft.
- kameras sind zur zeit an einem wendepunkt. vermutlich wuerde man
  heutzutage eine sCMOS benutzen, dann sollte man aber auf die
  triggereigenschaften achten
- arduino war nuetzlich um die elektronische triggerung ohne grossen
  aufwand umzusetzen (der hauptaufwand war oft nicht die
  zeitsteuerung, sondern eine ordentliche galvanische entkopplung der
  displays, die ist auch wichtig)
  - da unterscheiden sich die hersteller ohnehin sehr stark, bei dem
    dvi display war es erforderlich, testpunkte vom board abzugreifen
    und ueber adum zu entkoppeln, bei neueren varianten des usb boards
    kann man mittlerweile einfach einen stecker anstecken
- man kann relativ viel aufwand bei der rekonstruktion von optisch
  geschnittenen bildern betreiben, fuer das reale problem ist die
  vermeidung von artefakten dann oft doch nicht so wichtig (z.b. beads
  oder nuklei lokalisieren)
- transmission ist nicht ausreichend um wuermer zu untersuchen  
- vergleiche die folgenden displays:
  - holoeye (erwaehne triggerversuche, kalibrationsmessungen von
    uebertragungsfunktion und interpixel cross talk, hamamatsu)
  - forthdd (frage sie vielleicht, ob sie mir im nachhinein doch noch
    information geben)
  - ti dmd (sehr gute dokumentation, sehr viele funktionen; gut waere,
    wenn ich ein programm auf dem lokalen arm prozessor laufen lassen
    koennte, was die vollen 4000fps aus runlength (oder irgendwie
    komprimierten) daten vom usb aus erzeugen koennte
    - deflection angle defines f/# number of projection lens and
      therefore etendue, for good contrast f/# shouldn't be smaller
      than f/2.8
  - mma (naja)
* outlook
- den algorithmus zur beleuchtungsoptimierung kann man noch deutlich
  verbessern
  - gleichzeitige beleuchtung mehrerer nuklei
  - andere objektstrukturen (z.b. zylinder, axone)
    - 2010 hermann cuntz: One Rule to Grow Them All: A General Theory
      of Neuronal Branching and Its Practical Application
      - modell wie neuronen wachsen um axon oder dendritendichte
        vorherzusagen
  - voxels05_final
- eine genaue analyse einiger probleme mit wellenoptischer partiell
  kohaerenter theorie steht noch aus und waere interessant (nach
  wichtigkeit)
  - partiell kohaerente simulation des mma im schlierenoptischen system
    - sind graulevel vorteilhaft?
    - wuerde ein mma, bei dem alle spiegel in dieselbe richtung kippen
      die ettendue verdoppeln?
  - partiell kohaerente simulation des mma im shearing
    interferometrischen system
    - was ist die maximale ettendue eines wollaston prismas?
  - holographie methode mit extended source
  - Denkbar waere auch ein scannendes konfokales Mikroskop, dass an
    die Beleuchtungswinkel an jedem Punkt kontrolliert (siehe
    fig:hourglass-all-b).  Bisher wurden in der Literatur nur Systeme
    beschrieben, die die Phase des Beleuchtungslicht in der Pupille
    aendern (FIXME ref). Eine Adaption dieser Systeme zu einem
    spatio-angularen ist naheliegend und ich schlage vor, derartige
    Systeme auch untersucht werden sollten. Die Kombination von CLEM,
    einem Ringdetektor (vielleicht mit UZI) koennte die Bildgebung im
    Inneren lebender Organe (z.B. Gehirn) verbessern.

* appendix
** camera characterization
- Das ist wichtig, um Bilder vergleichen zu koennen, die mit
  verschiedenen Kameras (oder sogar mit PMT) aufgenommen wurden.
- get rid of grid lines
- give units
- andor basic code zur datenaufnahme
- python code fuer auswertung
** raytracer
- eigentlich sollte ich die formeln in den haupttext uebernehmen, ich
  weiss noch nicht so richtig, ob ich ueberhaupt einen appendix fuer
  den raytracer brauche
** mapping camera coordinates onto LCoS coordinates
- bilder und die formel beschreibe ich im haupttext, falls noch mehr
  notwendig ist, kommt das hier rein
** (contrast generation by fourier filtering the mma with incoherent illumination)
- das lasse ich weg
- eigentlich wollte ich wellenoptische simulation des
  schlierenoptischen systems zeigen, aber das finde ich nicht
  sonderlich interessant und ich kann es vermutlich nicht so gut
  machen wie mehta, sheppard (schliesslich ist eine partiell
  koheraente simulation notwendig und da muss man dann mit dem
  sampling im phase space aufpassen)
** hilo
**** local variance estimation (not mine, maybe into appendix?)
**** single side-band demodulation (not mine, maybe into appendix?)
**** TODO subtraction method (is this mine)
   - how to calculate the fudge factor eta?
   - can we make an argument with the OTF at the grating period?
   - they expect more formulas (how can i add more formulas)
   - i think i should modify the examples, to also show the sectioning
     performance
** forthdd dvi display connected to graphics card
- zeige meine messungen mit dem dvi anschluss
- erklaere aufbau und seine probleme

** intensity contrast generation by shearing interference
- beschreibe mma experimente

* zeitplan
  - abgabe spaetestens am 21. maerz, deadline: 1 woche vorher: 14. maerz
  - rainer und kai werden 1-2 wochen fuer korrektur brauchen
  - bis 14. februar text an rainer und kai geben
** aufgaben
   - stichpunktliste verbessern
   - ordentliche titel schreiben und unter jedem hinschreiben, was in
     dem kapitel gesagt werden soll
   - alle ergebnisse, die in der diskussion erwaehnt werden sollen
     auflisten
   - sektionen nach und nach abarbeiten
   - folgende reihenfolge (nach wichtigkeit)
     - motivation
     - geraetebeschreibung
     - optimierung
     - mma
     - results
     - holographie

     - structured illumination (ehemals appendix)

** generelle bemerkung
   - am anfang jeder sektion sollte der leser ein die story
     eingefuehrt werden, die ich dort rueberbringen will

   - list of recommended corrections
     - hinter jede korrektur beschreiben, wie ich sie bearbeitet habe



