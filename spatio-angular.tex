\chapter{The concept of spatio-angular microscopy}
\label{sec:concept}
\begin{summary}
  Here I introduce the spatio-angular microscope. First I motivate
  the concept of its illumination system using exemplary fluorophore
  distributions, that occur in typical specimen.

  Then I describe some decisions we faced during the initial design
  phase concerning the arrangement of optical components. Furthermore,
  I position our method among known approaches of light control for
  microscopy. Of all published techniques for excitation illumination
  control, the light field microscope \ref{levoy} (FIXME ref levoy)
  comes closest to our approach.  I explain differences between both
  techniques and discuss their respective pros and cons.  I address
  the peculiarities and limitations of the hardware components in
  later chapters (\ref{sec:dev1}, \ref{sec:mma} FIXME sec:dev1
  sec:mma).  Initially, the details would be detrimental to clarity.

  It turns out, that the effective use of the spatio-angular
  microscope, requires more knowledge about the specimen than a
  conventional or a SPIM microscope (\ref{spim} FIXME spim). Ideally the
  distribution of refractive index and fluorophores in the specimen
  should be known. If these parameters were precisely known, there
  would be no need for an image in the first place. However, while
  imaging a known specimen, sufficiently good predictions of these
  parameters can often be made. The higher the accuracy of these
  prognoses, the greater the reduction in phototoxicity will be.

  The computer-based selection of appropriate illumination masks
  requires the prediction, or at least an approximate estimation, of
  the three-dimensional distribution of light in the specimen.

  In the last part of this chapter, I describe the computational
  control loop in our spatio-angular
  microscope and touch topics of image processing.
\end{summary}
\section{Motivation}
In order to introduce the basic idea, underlying the spatio-angular
microscope, first I consider the distribution of excitation light in
the object of a conventional fluorescence microscope:
\figref{fig:hourglass-all}~a) schematically illustrates the side view
of the excitation beam path through objective lens and object in a
confocal microscope. A parallel beam with a circular cross-section
(this cross-section is not shown in the illustration) passes through
the lens. The lens focuses the light in its focal plane.

Between lens and focal plane the light rays form a convergent circular
cone. If refractive index variations in the object are negligible, the
light distribution below the plane of focus forms a cone as well, due
to symmetry.  Assuming a non- or weakly absorbing specimen, the energy
of the light in the circular cross-sections of the cone remains
constant\footnote{The ray-model is valid in large
  parts of \figref{fig:hourglass-all}~a), but not everywhere. The Law
  of Malus--Lupin states that rays and wavefronts are equivalent as
  long as rays do not intersect (caustic), or (FIXME formulas?) a
  strong intensity gradient occurs. Thus the ray-model is valid almost
  everywhere in the cone, except for a region with a distance of a few
  wavelengths to the edge, and the focus itself. While the wave-optical
  treatment of these areas is possible, it is computationally much
  more expensive than ray tracing. Wave-optical effects either lead to
  blurring in a length scale of a few wavelengths or intensity
  fluctuations due to interference. If necessary, we can use heuristics
  to find an upper bound for the local intensity from ray tracing
  results. For this reason we exclusively employ the ray-model in this
  work.}.


The fluorescent bead (1), in the focus, would therefore be excited
significantly more than the bead (2) outside the focal plane. Also
shown is the light distribution in the intermediate image plane.

The image of the in-focus bead (1) is sharp, i.e.\ its emanating
fluorescence light is concentrated on an area as small as possible and
positioned exactly on the detection pinhole. Conversely, the image of
the out-of-focus bead (2) is blurred and its fluorescence light is
distributed over a large area.

While only a tiny proportion of the light emitted by the out-of-focus
bead contributes to the detection signal of the confocal microscope---and
 therefore hardly affects the image quality, with respect to
overall phototoxicity of the full confocal system---it would be better
to prevent the excitation of the out-of-focus bead in the first place.

\begin{figure}[!hbt]
  \centering
  \svginput{.43}{hourglass-all}
  \caption{{\bf (a)} Two fluorescent beads are illuminated by all
    angles that the objective can (FIXME ich mag deliver nicht,
    accept?) deliver. The sharp image of the in-focus bead is
    deteriorated by blurry fluorescence of the out-of-focus bead (2). {\bf
      (b)} Angular control allows selective illumination of the
    in-focus bead (3), and results in a better image on the camera. {\bf
      (c)} Angular control, however, is insufficient, when an extended in-focus
    area is illuminated. {\bf (d)} Then, simultaneous spatial and
    angular control allows sequential excitation of the in-focus beads,
    while excluding the out-of-focus bead (10).}
  \label{fig:hourglass-all}
\end{figure}

The scheme in \figref{fig:hourglass-all}~b) demonstrates how
the light cone would have to be manipulated in order to exclude the out-of-focus
bead (4). The expected fluorescence image in the
intermediate image plane then contains only information from the
in-focus bead (3).

Viewed from the in-focus bead (3) the change in illumination
corresponds to a restriction of the light angles. Such control can be
exerted well through a mask in the other focal plane of the objective
lens (also denoted back focal plane or pupil plane).

Thus I have shown that it is useful and possible to equip a confocal
microscope with angular control. However, in our project we set out to
to build a wide field microscope in order to benefit from the speed
and quantum efficiency of modern cameras.  Nonetheless, a confocal
microscope with angular illumination control seems to have potential
and this subject is worthy further investigation.  See (FIXME) ref
sec:conclusion on page pageref sec:conclusion where I discuss a
combination of techniques that would lead to a system with promising capabilities.

I now turn to the task of bringing angular control to the wide field
microscope. \figref{fig:hourglass-all}~c) shows a configuration of the
specimen with two in-focus beads (5) and (6), and one out-of-focus
bead (7).  The angular illumination control is ineffective for this
arrangement of beads.  If both in-focus beads, (5) and (6), are exposed
simultaneously, i.e.\ an extended light source illuminates the entire field,
then the out-of-focus bead (7) is always excited.

Only by separate illumination of the in-focus beads (8)
and (9), as shown in \figref{fig:hourglass-all}~d), angular control
regains its function. For this reason a wide field system with angular
control, using a mask in the pupil, requires an additional mask in the
field.  Therefore, we call our method spatio-angular
microscopy. "Spatial" refers to the illumination control in the field
and "angular" refers to the control in the pupil plane.

% FIXME 2012 khodjakov schilling

\begin{figure}[!hbt]
  \centering
  \svginput{1.5}{memi-simple}
  \caption{Simplified schematic of the illumination system in our
    spatio-angular microscope. A homogeneous extended light source
    delivers light from the left. It is imaged by lenses $L_1$ and $L_2$ into
    the intermediate image $F'$. Then the tubelens $L_3$ and the
    objective $L_4$ form an image of $F'$ in the sample plane $F$. We
    use two spatial light modulators (SLM) to control the spatial and angular
light distribution in the specimen---the focal plane SLM in F', and the pupil plane SLM in
    P'.}
  \label{fig:memi-simple}
\end{figure}

\figref{fig:memi-simple} shows the optical path through our prototype
in a greatly simplified form.  From the left side, an extended light
source illuminates the system. A sequence of telecentric lenses $L_1$,
$L_2$, $L_3$ and the objective lens $L_4$ image the light source from
F'' into the front focal plane (indicated by F, for field). The
etendue $G=\frac{\pi}{4}(D_\textrm{field}\textrm{NA})^2$---also called
information capacity, light gathering capacity or space-bandwidth
product; its value is related to the number of point spread functions
that can be resolved in the field (FIXME check definitions, put
formula somewhere else, area of the light distribution convolved with
the solid angle))---of the light source must be large enough to
simultaneously fill both, the pupil P as well as the field F.

In each of the two planes P' and F' we place a spatial light modulator (SLM)
that allows to control the intensity of the transmitted light.

Looking at the scheme in \figref{fig:memi-simple}, one might argue
that we could save a lens, if we placed the pupil plane SLM into P
instead of P'. There are three reasons why this is neither possible,
nor beneficial: First, the pupil of modern high-performance objective
lenses is not accessible\footnote{This is due to historical reasons.
  The length of objective lenses was defined, such that no refucusing
  would be necessary, when changing the objectives. In the case of
  Zeiss lenses, their length is \unit[45]{mm}. Nowadays, it would be
  easy to compensate different objective lengths using the ubiquitous
  motorized focus control.  Rather than continuing to be restricted by
  an antiquated standard, Manufacturers should produce longer
  High-Performance Lenses with accessible pupil plane.}  Second, the
detection path for fluorescent light should contain as few optical
components as possible and we can definitely not afford it to be
blocked by a SLM.  Third, the two masks induce non-linear, and
therefore difficult to predict, filtering of spatial frequencies. An
analysis requires consideration of partial spatial coherence, but it
should be clear (FIXME) that only the final SLM always delivers a good
image, mostly independent of the state of the SLM upstream.

Considering the fact that the image of the focal plane SLM is most
important to us, we decided to place it downstream of the pupil plane
SLM. The focal plane SLM may disturb the image of the pupil plane SLM
in P, but we can always produce very
fine, high-contrast structures in the sample F.

The abiltity to achieve high resolution in the field is the main
difference between our approach and Levoys light field microscope.  In
the light field microscope, the density of the microlenses noticeably
limits the resolution. As opposed to our system, the light field microscope allows to
control the angle of incidence in all field positions independently.
But, additionally to the reduced focal plane resolution, this requires a single high-resolution SLM with a comparatively
low refresh rate. We use two small SLMs, which can each achieve
\unit[1]{kHz} frame rate and enable interesting experiments,
e.g.\ optogenetic control of neuron activities.

Furthermore, structured illumination with high resolution patterns allows us to
circumvent the missing cone problem of the widefield microscope.
Later I will show that depth
discrimination improves with higher resolution patterns (FIXME ref).
\section{An imaging protocol with spatio-angular illumination control}
\subsection{Description of an exemplary biological specimen}
Now I describe time-lapse imaging with low phototoxicity using the
example of developing \celegans\ embryos. As we will discuss in later chapters, so far we did not reach
the point of being able to image the development of a real embryo. Key
problems are  the low light throughput of the illumination
system and the length of time necessary to update images on the focal
plane display. Nevertheless, I always kept this example in mind,
while I was developing the control software for our microscope.

We use embryos which  were genetically modified\footnote{Our strain has WormBase ID AZ212.}
to include eGFP tagged histones (enhanced green fluorescent protein,
excitation maximum \unit[488]{nm}, emission maximum
\unit[509]{nm}). Histones are incorporated into the chromatin during cell
divisions, i.e.\ the nuclei of our worms fluoresce green.
 The mother worm passes a sufficient amount of these
proteins into the cytoplasm of the embryo. In the beginning of its development the embryo
entirely relies on this supply  (FIXME vorrat) of histones. Only in a much later stage,
it will form its own histones. 

During the first few hours, the embryo develops confined within the
constant volume of its egg, which has an ellipsoidal shape,
extends 40 to 60 microns and can be readily observed using a
$63\times$ objective lens. Cell divisions occur every few minutes.
During development the nuclei get smaller and more
dense. In order to track the fate of all individual cells it is sufficient, to
capture one stack per minute with 20 layers at a distance of 1~micron.
\subsection{Preparation of living embryo samples}
For an observation a worm is cut and the embryos are placed on an (FIXME wormbook procedure)
agarose pad, so that they stay immobile during imaging. Of these
embryos, the experimenter chooses a young specimen, that has not yet
divided. We avoid to use fluorescence excitation for this step.
The undivided embryos can be distinguished using
the less phototoxic differential interfernce contrast (DIC) imaging
mode.

\subsection{Sectioning through structured illumination}
To get an estimate of the initial conditions of the fluorophore
distribution in the embryo we obtain the very first stack with
structured illumination and no angular control. We use this
method to avoid the missing cone problem of the
widefield microscope. Perhaps for our particular task of finding
the position of the nucleus within the egg, widefield images would be
just sufficient.  However, for our spatio-angular method, knowledge
about the fluorophore distribution is very important and therefore we
built our microscope such that we can obtain optical sections.

We compared conventional structured illumination using max$-$min
(FIXME) reconstruction with laser and LED illumination. Although LED
illumination resulted in excellent optical sections, the reconstruction of
laser illuminated images contained artifacts.

{\color{red}
- (FIXME muss das vielleicht in appendix?) In einem ersten
Entwicklungsschritt, bevor InVision uns den Prototyp fuer das
spatio-angulare Mikroskop zur Verfuegung stellte, setzten wir einen
SLM in die Zwischenbildebene. Auf dem SLM wurden vier Streifenmuster
angezeigt und Wir verglichen einen 70mW 473nm DPSS laser mit 470nm LED
Beleuchtung (CoolLED).}

Therefore, we decided to implement HiLo (see Appendix FIXME). With
this algorithm, we obtain artifact-free optical sections, regardless
of the illumination source. As another advantage the HiLo method
increases acquisition speed, as only two raw images per slice are
necessary.


{\color{red} wir haben artefakte in der max-min rekonstruktion
  beobachtet, wenn wir ein grobes streifenmuster (8 forthdd slm pixel
  periode) mit laser beleuchtet haben

     - irgendwann hat rainer das erklaert aber ich kann mich nicht
       mehr dran erinnern aber es waere cool, wenn ich die story
       bringen koennte
     
- grobes gitter heisst im amplitudenbild: einige ordnungen (nicht
       nur 3) gehen durch die bfp

     - irgendwie kam es dadurch im intensitaetsbild zu einigen hoehere
       ordnungstermen

     - bei LED (extended source) werden die weggemittelt, bei laser
       nicht

       - ein bisschen kopfzerbrechen bereitet mir noch der bias 

       - im paper habe ich das nicht verstanden [2011 mertz Optically
       sectioned in vivo imaging with speckle illumination HiLo
       microscopy]

       - aber ich habe ihr java imagej plugin decompiliert bekommen
       und koennte versuchen ihre implementierung zu verstehen
       (andererseits ist mir das jetzt ziemlich egal)

       - unter equation 10: The first two terms are variance
       contributions of shot noise. Filtering has the effect of
       reducing noise variance and is taken into account with the
       integral term. This bias must thus be subtracted from
       $\sigma^2$ prior to the evaluation of C. We have also not
       considered the effects of pixelation in the CCD camera. If the
       pixel size is non-negligible ..  }

\subsection{Computer model for the integration of a priori knowledge
  about the biological events}
Given an initial measurement of the fluorophore distribution of the
embryo, I employ a computational algorithm to find good illumination
conditions for subsequent stack acquisitions. An important
requirement is that the computer can estimate, which areas of the
sample should be protected from illumination. 

For our test system, the \celegans\ embryo, it is a promising approach
to represent its three-dimensional fluorophore distribution by a simple
model: Spheres encompassing the nuclei, indicate regions with fluorophores. When in focus, the
spheres are the source of useful, informative fluorescence signal,
but should be protected from (FIXME from or against) exposure when out of
focus.

As I mentioned earlier, there are also unused histones with
fluorophores outside of the nuclei. The images reveal that they occur
in the cytoplasm at a much lower concentration than in the
nuclei. Fluorophores in the cytoplasm have a smaller phototoxic
effect, because any radicals they produce are much less likely to
reach the DNA and therefore inflict substantially less damage.
In the following my goal is to protect only out-of-focus nuclei from
exposure. The regions in between are used to bring the light in.


During observation, the nuclei, i.e.\ the centers of the spheres, move
slowly within the embryo. For small periods of time we can describe
this movement using a vector field of growth velocities.

A cell
division announces itself by a change of the fluorophore distribution of the nucleus
due to chromatin condensation and spindle formation. Therefore, whenever the computer
detects such changes in the images, in one of the following time
steps an additional sphere should be introduced to account for the new
daughter cell.

So far I have only implemented a simple algorithm, to convert a time
series of image volumes from a confocal microscope into a sphere model
(FIXME difference of Gaussians and radius determination blob paper).
One of our project partners (Jean-Yves Tinevez,
http://fiji.sc/wiki/index.php/TrackMate) developed a more
sophisticated plug-in for ImageJ, that provides the lineage tree and
snapshots of the developing cells (see \figref{fig:trackmate}).
\begin{figure}[!hbt]
  \centering
  \pdfinput{8cm}{TrackMate_Celegans_lineage}
  \caption{ A detail of a lineage tree visualized in TrackScheme. An
    image of each nucleus is shown in each time step. Note how the
    elongated structure before cell division events. (FIXME ask jean-yves if
    i can use this, add time axis)}
  \label{fig:trackmate}
\end{figure}
Before our microscope can be used for our biological problem, the
computer model has to be extended so that it reliably tracks the
movement of nuclei.  Overlooking any nucleus would prevent this nucleus from being 
imaged in later acquisitions and would be a setback for the experiment.  Estimating the
vector field of growth velocities helps to track nuclei more robustly
and allows to predict their positions for the next exposure.


Unfortunately, currently we have not implemented programs that would
fulfill the requirements for imaging a developing embryo.  However, in
the following text I assume that the described position predictions
were available and I discuss how I determine masks for the focal
plane and pupil plane SLM.  

\subsection{Illumination optimization by means of raytracing}
I now discuss a method to find both SLM masks for image acquisitions
with minimal phototoxicity. First I define a mask for the focal plane
SLM:

From the predicted arrangement of spheres we select in-focus nuclei
by intersecting the model with a planar surface. I then define focal
plane SLM masks to selectively illuminate each of the in-focus nuclei,
by drawing a bright disk in the appropriate position.

Based on such a mask, we can determine which angles can illuminate the
in-focus target nucleus, without exposing out-of-focus nuclei.

As we already explained at the beginning of the chapter (FIXME
pageref), ray-optical theory suffices to describe the light
distribution within the sample.

I connect the periphery of an out-of-focus nucleus with a point
inside the in-focus target. This defines a circular cone of rays, that
are propagated through the objective lens. Their
intersection with the pupil plane results in a figure that still very
much resembles a circle---I found that already seven rays lead to good
representation of its perimeter.  I compute these figures for every
out-of-focus nucleus and for a few in-focus targets points within the
bright areas of the focal plane pattern. In this manner I construct
the desired mask for the pupil plane SLM.

In order to trace the rays into the pupil, I need the design parameters of
the objective lens (vertex position, curvature and material for all
surfaces). Unfortunately, these rarely are publicly
available for high-performance objective lenses. Nevertheless, in
chapter (FIXME) I use a simpler model of the objective lens, that
requires only three parameters: focal length, refractive index of the
immersion medium and numerical aperture. These are always known.

Additionally, I have adapted the model for non-index-matched
embedding of the specimen. This problem occurs, when the embryo is
illuminated with an oil immersion objective, using HILO (FIXME
ref). It should be noted, however, that good image quality of the
embryo can only be achieved with an objective lens that has the same
immersion index as the embryo. Otherwise data from 20 microns within
the sample will be severely deteriorated by spherical aberrations.
